---
pdf_document: default
authors: "Alvaro Cervan, Luca Renz, Rafaella Miranda-Sousa"
date: "2024-01-10"
output:
  word_document: default
  pdf_document: default
title: "ML1"
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_packages, echo =FALSE, cache=TRUE}

#Install and import libraries.
if (!require("car")) install.packages("car")  # Support Vector Machine (SVM)
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("ROI")) install.packages("ROI")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("corrplot")) install.packages("corrplot")
if (!require("dplyr")) install.packages("dplyr")
if (!require("GGally")) install.packages("GGally")
if (!require("mgcv")) install.packages("mgcv")  # Generalised Additive Model (GAM)
if (!require("nnet")) install.packages("nnet")  # Neural Networks
if (!require("e1071")) install.packages("e1071")  # Support Vector Machine (SVM)
if (!require("MASS")) install.packages("MASS")
if (!require("arm")) install.packages("arm")

library(car)
library(readr,quietly = T)
library(ggplot2, quietly = T)
library(ROI, quietly = T)
library(tidyverse, quietly = T)
library(lubridate, quietly = T)
library(corrplot, quietly = T)
library(dplyr)
library(GGally)
library(mgcv)  # For Generalised Additive Models
library(nnet)  # For Neural Networks
library(e1071)  # For Support Vector Machine
library(arm)
library(caret)

```
Notizen Rafi
SVM Teil:
  Cross validation or other methods for model comparing must be used on one single
methods (e.g. you use Cross Validation to compare 2-3 SVM models).
• Students are free to choose a measure of fit that they find more appropriate.
• In case students cannot find an appropriate measure of fit, they can use the Root Mean
Squared Error (RMSE).

Schliesslich ist zu beachten, dass die Zusammenstellung von Dokumenten einige Zeit in Anspruch nehmen kann... insbesondere wenn komplexe
Modelle angepasst werden
- In diesen Fällen können Sie die Argumentationsoption cache = TRUE verwenden, so dass ein Chunk nur dann neu ausgewertet wird
nur dann neu ausgewertet wird, wenn er seit der letzten Kompilierung geändert wurde. Wenn der Chunk unverändert blieb
unverändert, dann werden die alten Ergebnisse verwendet



# Data Preprocessing

Aus Quelle:
  Some predictors such as carrying capacity and seat number are removed from the dataset prior
to data analysis and modeling since they are not correctly coded.


CHATGPT
CCM TON
Es macht keinen Sinn, dass Fahrzeuge einen Wert von 0 für die Variable CCM_TON haben, wenn diese Variable den Hubraum oder das Gewicht des Motors in Kubikzentimetern (ccm) oder Tonnen angibt.
Warum?
  Der Hubraum (ccm) gibt das Volumen der Zylinder eines Verbrennungsmotors an. Ein Wert von 0 wäre unplausibel, da ein Fahrzeug ohne Hubraum keinen funktionsfähigen Motor hätte.
Wenn CCM_TON das Gewicht des Motors in Tonnen angibt, wäre ebenfalls ein Wert von 0 unplausibel, da ein Fahrzeug ohne Motorgewicht nicht funktionsfähig wäre.

```{r data_prep, echo=FALSE, cache=TRUE}

# DATA LOAD
raw_dat_motor <- read_csv("data/motor_data14-2018.csv", show_col_types = FALSE)

dim(raw_dat_motor)
str(raw_dat_motor)

#DATA PREP

#EFFECTIVE_YR
#Entfernen der Spalte EFFECTIVE_YR (Hat keinen Nutzen, da nicht entziffert werden kann)
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "EFFECTIVE_YR")]

#CARRYING_CAPACITY
#Entfernen der Spalte CARRYING_CAPACITY
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "CARRYING_CAPACITY")]

#CLAIM_PAID
raw_dat_motor$CLAIM_PAID_USD <- ifelse(is.na(raw_dat_motor$CLAIM_PAID), 0, raw_dat_motor$CLAIM_PAID)
raw_dat_motor$CLAIM_PAID <- ifelse(raw_dat_motor$CLAIM_PAID_USD == 0, "NO", "YES")

# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

#SEX
raw_dat_motor$SEX <- factor(raw_dat_motor$SEX, 
                            levels = c(0, 1, 2), 
                            labels = c("Legal entity", "Male", "Female"))
table(raw_dat_motor$SEX)

#INSR_BEGIN
raw_dat_motor$INSR_BEGIN <- dmy(raw_dat_motor$INSR_BEGIN)

#INSR_END
raw_dat_motor$INSR_END <- dmy(raw_dat_motor$INSR_END)

#DURATION
raw_dat_motor$DURATION <- as.numeric(as.Date(raw_dat_motor$INSR_END) - as.Date(raw_dat_motor$INSR_BEGIN))
hist(raw_dat_motor$DURATION)
#Gleiche DURATION (Vertragsdauer) zur Vergleichbarkeit
raw_dat_motor <- raw_dat_motor[raw_dat_motor$DURATION == 364, ]

#Jahr des Versicherungsbeginns extrahieren und als neue Variable hinzufügen
raw_dat_motor$START_INS_YR <- year(as.Date(raw_dat_motor$INSR_BEGIN))

#INSR_TYPE
raw_dat_motor$INSR_TYPE <- factor(raw_dat_motor$INSR_TYPE, 
                                  levels = c(1201, 1202, 1204), 
                                  labels = c("Private", "Commercial", "Motor trade road risk"))

#INSURED_VALUE
#Überprüfen der Anzahl der fehlenden Werte
missing_values <- sum(is.na(raw_dat_motor$INSURED_VALUE))
cat("Fehlende Werte in INSURED_VALUE:", missing_values, "\n")

#Zusammenfassung der statistischen Kennzahlen
summary_stats <- summary(raw_dat_motor$INSURED_VALUE)
cat("Zusammenfassung der statistischen Kennzahlen von INSURED_VALUE:\n")
print(summary_stats)

#Ermittlung der Anzahl der Einträge, die 0 als Wert haben
zero_values <- sum(raw_dat_motor$INSURED_VALUE == 0, na.rm = TRUE)
cat("Anzahl der Einträge mit dem Wert 0 in INSURED_VALUE:", zero_values, "\n")

#Überprüfe, wie viele Datensätze betroffen sind
zero_insured_value <- raw_dat_motor[raw_dat_motor$INSURED_VALUE == 0, ]
cat("Anzahl der Datensätze mit INSURED_VALUE = 0:", nrow(zero_insured_value), "\n")

#Zusammenfassung der betroffenen Datensätze nach verschiedenen Variablen, um Muster zu erkennen
cat("Verteilung der Versicherungstypen (INSR_TYPE) bei INSURED_VALUE = 0:\n")
table(raw_dat_motor$INSR_TYPE) #Alle
print(table(zero_insured_value$INSR_TYPE)) #nur 0

cat("\nVerteilung der Fahrzeugtypen (TYPE_VEHICLE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$TYPE_VEHICLE))

cat("\nVerteilung der Fahrzeugnutzung (USAGE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$USAGE))

#Statistische Kennzahlen für andere Variablen bei INSURED_VALUE = 0 (z.B. PREMIUM)
cat("\nZusammenfassung der Prämien (PREMIUM) bei INSURED_VALUE = 0:\n")
summary(zero_insured_value$PREMIUM)

#Visualisierung der Fahrzeugnutzung bei INSURED_VALUE = 0
ggplot(zero_insured_value, aes(x = USAGE)) +
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Verteilung der Fahrzeugnutzung bei INSURED_VALUE = 0", x = "Fahrzeugnutzung", y = "Anzahl") +
  theme_minimal()

#Fazit: Es wurde kein Zusammenhang festgestellt. Vermutlich ist der Versicherungswert von 0 darauf zurückzuführen, dass gesetzlich nur eine Haftpflichtversicherung erforderlich ist. In diesen Fällen gibt es keinen festgelegten Wert für Schäden am Fahrzeug selbst. Daher werden Datensätze mit einem INSURED_VALUE von 0 aus der Analyse entfernt, da sie keine relevanten Informationen für die Bewertung von Fahrzeugwerten enthalten.

#Entfernen der Zeilen, bei denen INSURED_VALUE gleich 0 ist
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE != 0, ]

#Überprüfen, ob die Zeilen erfolgreich entfernt wurden
cat("Anzahl der verbleibenden Datensätze:", nrow(raw_dat_motor), "\n")

#Verteilung von INSURED_VALUE visualisieren (Histogramm)
ggplot(raw_dat_motor, aes(x = INSURED_VALUE)) +
  geom_histogram(binwidth = 50000, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Verteilung von INSURED_VALUE", x = "Versicherter Wert", y = "Häufigkeit") +
  theme_minimal()

#Boxplot zur Identifizierung von Ausreissern
ggplot(raw_dat_motor, aes(y = INSURED_VALUE)) +
  geom_boxplot(fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "Boxplot von INSURED_VALUE", y = "Versicherter Wert") +
  theme_minimal()

#Überprüfung der statistischen Kennzahlen ohne die 0-Werte
cat("Zusammenfassung der statistischen Kennzahlen ohne 0-Werte:\n")
print(summary(raw_dat_motor$INSURED_VALUE))

#Verteilung der log-transformierten INSURED_VALUE (nur für nicht-null Werte)
ggplot(raw_dat_motor[raw_dat_motor$INSURED_VALUE > 0, ], aes(x = log(INSURED_VALUE))) +
  geom_histogram(binwidth = 0.2, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Log-transformierte Verteilung von INSURED_VALUE (ohne Nullwerte)", x = "log(Versicherter Wert)", y = "Häufigkeit") +
  theme_minimal()

summary(raw_dat_motor$INSURED_VALUE)

#Ausreisser INSURED_VALUE entfernen 
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE >= 10, ]
summary(raw_dat_motor$INSURED_VALUE)

#Workspace
rm(zero_insured_value)

#PREMIUM
#Uberpruefung ob entfernen von PREMIUM = 0 vom Datensatz valide ist
data.frame(
  PREMIUM_0_Percent = round(100 * sum(raw_dat_motor$PREMIUM == 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_NA_Percent = round(100 * sum(is.na(raw_dat_motor$PREMIUM)) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_MORE_Percent = round(100 * sum(raw_dat_motor$PREMIUM > 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4)
)

#Entfernen der Zeilen, bei denen PREMIUM NA oder 0 ist
raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$PREMIUM) | raw_dat_motor$PREMIUM == 0), ]


# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

# OBJECT_ID
# Anzahl der Gesamtzeilen im Datensatz
total_rows <- nrow(raw_dat_motor)

# Anzahl der einzigartigen OBJECT_IDs
unique_object_ids <- length(unique(raw_dat_motor$OBJECT_ID))

# Überprüfen, ob OBJECT_IDs einmalig sind
if (total_rows == unique_object_ids) {
  cat("Die OBJECT_IDs sind einmalig.\n")
} else {
  cat("Die OBJECT_IDs sind NICHT einmalig.\n")
  cat("Anzahl der Duplikate:", total_rows - unique_object_ids, "\n")
  
  # Häufigkeit der OBJECT_IDs
  object_id_counts <- table(raw_dat_motor$OBJECT_ID)
  
  # Durchschnittliche und maximale Häufigkeit von OBJECT_ID
  avg_object_id_freq <- mean(object_id_counts)
  max_object_id_freq <- max(object_id_counts)
  
  cat("Durchschnittliche Häufigkeit der OBJECT_ID:", round(avg_object_id_freq, 3), "\n")
  cat("Maximale Häufigkeit der OBJECT_ID:", max_object_id_freq, "\n")
  
  # Häufigkeit der Kombination von OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE und PREMIUM
  combo_counts <- raw_dat_motor %>%
    group_by(OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM) %>%
    summarise(count = n(), .groups = 'drop')
  
  # Durchschnittliche und maximale Häufigkeit der Kombination
  avg_combo_freq <- mean(combo_counts$count) # Durchschnittliche Häufigkeit der Kombination
  max_combo_freq <- max(combo_counts$count)   # Maximale Häufigkeit der Kombination
  
  cat("Durchschnittliche Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", round(avg_combo_freq, 3), "\n")
  cat("Maximale Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", max_combo_freq, "\n")
}

#Teilweise gibt es bei CLAIM_PAID== YES eine vervielfachung
#Korrektur bzw. entfernen dieser mehrfachen Zeilen
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSR_TYPE, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  # Zähle die Anzahl der Zeilen in jeder Gruppe
  mutate(group_size = n()) %>%
  ungroup() %>%
  # Entferne Zeilen nur, wenn es eine Doppelzeile gibt und CLAIM_PAID == "NO" und CLAIM_PAID_USD <= 1
  filter(!(group_size > 1 & CLAIM_PAID == "NO" & CLAIM_PAID_USD <= 1)) %>%
  dplyr::select(-group_size)  # Entferne die Hilfsspalte

#Korrektur Wiederspruch bei INSR_TYPE
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  filter(!(n() > 1 & INSR_TYPE != "Commercial")) %>%  # Behalte nur die Zeilen mit "Commercial"
  ungroup()  # Ungroup, um das Gruppierungsobjekt zu entfernen

# Clear Workspace
rm(list = setdiff(ls(), "raw_dat_motor"))


#PROD_YEAR
#Zeilen mit PROD_YEAR NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$PROD_YEAR),]
summary(raw_dat_motor$PROD_YEAR)

#SEATS_NUM
#Analyse SEATS_NUM: Anzahl der Zeilen mit SEATS_NUM == 0, NA und anderen Werten
data.frame(
  SEATS_NUM_0 = sum(raw_dat_motor$SEATS_NUM == 0, na.rm = TRUE),
  SEATS_NUM_NA = sum(is.na(raw_dat_motor$SEATS_NUM)),
  SEATS_NUM_OTHER = sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE)
)
#Relativ: Prozentsatz der Zeilen mit SEATS_NUM == 0, NA oder anderen Werten
data.frame(
  SEATS_NUM_0_or_NA_Percent = 100 * sum(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0) / nrow(raw_dat_motor),
  SEATS_NUM_OTHER_Percent = 100 * sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE) / nrow(raw_dat_motor)
)
#Zeilen mit SEATS_NUM NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$SEATS_NUM),]
summary(raw_dat_motor$SEATS_NUM)

#Problematik: Es gibt SEATS_NUM mit 0

##Erstellen separater Datensätze für SEATS_NUM == 0 und SEATS_NUM > 0
#data_seats_num_0 <- subset(raw_dat_motor, SEATS_NUM == 0)
#data_seats_num_other <- subset(raw_dat_motor, SEATS_NUM > 0 & !is.na(SEATS_NUM))
## Tabellen der Fahrzeugtypen für beide Datensätze
#table(data_seats_num_0$TYPE_VEHICLE)
#table(data_seats_num_other$TYPE_VEHICLE)

##SEATS_NUM Alternative 1: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
##Liste der Fahrzeugtypen, bei denen SEATS_NUM == 0 unplausibel ist (Trailers and semitrailers, Tractor, Tanker werden gelassen)
#unplausible_types <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Station Wagones", "Tanker", "Truck")
##Entfernen der Zeilen, bei denen SEATS_NUM == 0 und der Fahrzeugtyp unplausibel ist
#raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$SEATS_NUM == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types), ]
#
#
##SEATS_NUM Alternative 2: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
#raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0), ]
#
##SEATS_NUM Alternative 3: Entfernen der SEATS_NUM-Spalte, da viele NA und schlechte Datenqualität
##raw_dat_motor <- subset(raw_dat_motor, select = -SEATS_NUM)

#TYPE_VEHICLE
#Entfernen der Zeilen, bei denen TYPE_VEHICLE == "Trade plates" Da zu wenige Auspraegungen (5)
#table(raw_dat_motor$TYPE_VEHICLE)
raw_dat_motor <- raw_dat_motor[raw_dat_motor$TYPE_VEHICLE != "Trade plates", ]

#CCM_TON
summary(raw_dat_motor$CCM_TON)
#Relativ CCM_TON 0
data.frame(
  CCM_TON_0_Percent = 100 * mean(raw_dat_motor$CCM_TON == 0, na.rm = TRUE),
  CCM_TON_MORE_Percent = 100 * mean(raw_dat_motor$CCM_TON > 0, na.rm = TRUE))
# Erstellen separater Datensätze für CCM_TON == 0 und CCM_TON > 0
data_CCM_TON_0 <- subset(raw_dat_motor, CCM_TON == 0)
data_CCM_TON_other <- subset(raw_dat_motor, CCM_TON > 0 & !is.na(CCM_TON))
# Tabellen der Fahrzeugtypen für beide Datensätze
table(data_CCM_TON_0$TYPE_VEHICLE)
table(data_CCM_TON_other$TYPE_VEHICLE)
# Liste der Fahrzeugtypen, bei denen CCM_TON == 0 unplausibel ist (Tractor,Trailers and semitrailers werden gelassen)
unplausible_types_ccm <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Truck", "Station Wagones", "Tanker", "Special construction")
# Entfernen der Zeilen, bei denen CCM_TON == 0 und der Fahrzeugtyp unplausibel ist
raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$CCM_TON == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types_ccm), ]


#USAGE
#table(raw_dat_motor$USAGE)
#Wenige Ausprägungen entfernen
raw_dat_motor <- subset(raw_dat_motor, !(USAGE %in% c("Fire fighting", "Learnes", "Others")))



#MAKE
#Zeilen mit MAKE NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$MAKE),]
#MAKE in Grossbuchstaben umwandeln
raw_dat_motor$MAKE <- toupper(raw_dat_motor$MAKE)

#Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
#Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")
# Behalten von Zeilen, in denen MAKE mit Buchstaben beginnt
raw_dat_motor <- raw_dat_motor[grepl("^[A-Za-z]", raw_dat_motor$MAKE), ]
table(raw_dat_motor$MAKE)


#Manuelle Korrekturen von MAKE
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PORCHE", "FORSCHE")] <- "PORSCHE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE == "YAMHA"] <- "YAMAHA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("VOLKSWAGON", "VOLKS WAGON")] <- "VOLKSWAGEN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("TOYOTAA", "TOYOTA*", "TOYTA", "TOYOTA AUTOMOBILE",
                                             "TOYATA", "T0Y0TA", "COMPACT YARIS", "YARIS",
                                             "LAND CRUISER", "VITZ")] <- "TOYOTA"
raw_dat_motor$MAKE[grepl("^TOYOTA", raw_dat_motor$MAKE)] <- "TOYOTA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("NISAN", "NISSAN*")] <- "NISSAN"
raw_dat_motor$MAKE[grepl("^NISSAN", raw_dat_motor$MAKE)] <- "NISSAN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENGE  ROVER", "RANGEROVER")] <- "RANGE ROVER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENALT", "RENUALT", "RENAULT/STOLARCZYK", "RENAULT*")] <- "RENAULT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PEUGEOUT", "PEJOT", "PAGOT")] <- "PEUGEOT"
raw_dat_motor$MAKE[grepl("^PEUGEOT", raw_dat_motor$MAKE)] <- "PEUGEOT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("BMB")] <- "BMW"
raw_dat_motor$MAKE[grepl("^BMW", raw_dat_motor$MAKE)] <- "BMW"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MISTIBUSH", "MITSUBISHI*", "MITSUBUSHI")] <- "MITSUBISHI"
raw_dat_motor$MAKE[grepl("^FORD", raw_dat_motor$MAKE)] <- "FORD"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SPORTAGE")] <- "KIA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MERCEEDES", "MERCEEDICE", "MERCEDICE", "MERCHEDES")] <- "MERCEDES"
raw_dat_motor$MAKE[grepl("^MERCEDES", raw_dat_motor$MAKE)] <- "MERCEDES"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SUZIKE")] <- "SUZUKI"
raw_dat_motor$MAKE[grepl("^SUZUKI", raw_dat_motor$MAKE)] <- "SUZUKI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HYUNDI GETZ")] <- "HYUNDAI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("ISUSU")] <- "ISUZU"
raw_dat_motor$MAKE[grepl("^ISUZU", raw_dat_motor$MAKE)] <- "ISUZU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("FRANKUN IVECO")] <- "IVECO"
raw_dat_motor$MAKE[grepl("^IVECO", raw_dat_motor$MAKE)] <- "IVECO"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LANDROVER")] <- "LAND ROVER"


raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DONGFANG", "DONFING", "DONG FENGSHEN", "DONG FENG")] <- "DONGFENG"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MAHANDRA")] <- "MAHINDRA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HOLAND CAR")] <- "ABAY"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("CALABRASE")] <- "CALABRESE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("GELYION", "GENLION", "GELION", "GENLYONIVECO", "HONGYAN")] <- "GENLYON"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DHATSU", "DIATSU", "DIAHATSU")] <- "DAIHATSU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DAWOO", "DAWWO", "DEAWOO", "DEAWOO USE")] <- "DAEWOO"
raw_dat_motor$MAKE[grepl("^LIFAN", raw_dat_motor$MAKE)] <- "LIFAN"
raw_dat_motor$MAKE[grepl("^BAIC", raw_dat_motor$MAKE)] <- "BAIC"
raw_dat_motor$MAKE[grepl("^LOADER", raw_dat_motor$MAKE)] <- "LOADER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MOTOR CYCLE", "MOTOR  CYCLE")] <- "MOTORCYCLE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("AUTO", "AUTOMOBIL")] <- "AUTOMOBILE"
raw_dat_motor$MAKE[grepl("^CATERPILLAR", raw_dat_motor$MAKE)] <- "CATERPILLAR"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LIBER DOZER", "LIBERR MOBILE CRANE",
                                             "LIEBERR MOBILE CRANE", "LEABER CATO CRANE",
                                             "LEBHER CRANE", "CRANE LEBEHER",
                                             "CRANE LEBHERER", "LIBER", "LIBEHER CRANE",
                                             "LIBERR MOBILECRANE", "CRANELEBHER")] <- "LIEBHERR"

#table(raw_dat_motor$MAKE)

#Zähle die Anzahl der Einträge pro MAKE, wo CLAIM_PAID == "YES"
count_claims_paid <- raw_dat_motor %>%
  group_by(MAKE, CLAIM_PAID ) %>%                 # Gruppiere nach MAKE
  summarise(count = n()) %>%        # Zähle die Einträge pro Gruppe
  arrange(desc(count)) 

###############################################################################################


#Liste der gewünschten Fahrzeughersteller (Make)
selected_makes <- c("TOYOTA", "ISUZU", "NISSAN", "IVECO", "SINO HOWO", 
                    "MITSUBISHI", "BISHOFTU", "LIFAN", "FORD", "HYUNDAI", 
                    "MAZDA", "GEELY", "DAEWOO", "MERCEDES", "TATA", 
                    "FIAT", "SINO", "SUZUKI", "GENLYON", "RENAULT")

#Filtern des Datensatzes nach den ausgewählten Fahrzeugherstellern
clean_dat_motor <- subset(raw_dat_motor, MAKE %in% selected_makes)

#Wenige Ausprägungen entfernen
#table(clean_dat_motor$SEX) #OK

#table(clean_dat_motor$USAGE)
clean_dat_motor <- subset(clean_dat_motor, !(USAGE %in% c("Agricultural Any Farm",
                                                          "Agricultural Own Farm",
                                                          "Special Construction", "Taxi")))

#table(clean_dat_motor$TYPE_VEHICLE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(TYPE_VEHICLE %in% c("Tractor")))

#table(clean_dat_motor$INSR_TYPE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(INSR_TYPE %in% c("Motor trade road risk")))

#table(clean_dat_motor$MAKE)

#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

#New Variable: age_vehicle
clean_dat_motor$AGE_VEHICLE <- 2018 - clean_dat_motor$PROD_YEAR
#Entfernen von PROD_YEAR
clean_dat_motor<- clean_dat_motor[,-8]



#New variable: AMOUNT_CLAIMS_PAID (Number of previous claims per object ID)
clean_dat_motor <- clean_dat_motor %>%
  # Für jede object_ID und jedes Startjahr, kumuliere die Anzahl vorheriger Claims mit "YES"
  group_by(OBJECT_ID) %>%
  arrange(OBJECT_ID, START_INS_YR) %>%
  mutate(
    AMOUNT_CLAIMS_PAID = sapply(seq_along(START_INS_YR), function(i) {
      sum(CLAIM_PAID[1:(i-1)] == "YES" & START_INS_YR[1:(i-1)] < START_INS_YR[i])
    })
  ) %>%
  ungroup()
###############################################################################################

#Vergleich zum Rohdatensatz
#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))


###############################################################################################

#NA
colSums(is.na(raw_dat_motor)) 
colSums(is.na(clean_dat_motor)) 

#Entfernen der Variablen 'versicherungsbeginn' und 'versicherungsende'
clean_dat_motor <- subset(clean_dat_motor, select = -c(INSR_BEGIN, INSR_END, DURATION))

# Neuanordnung der Spalten: Zuerst OBJECT_ID, dann START_INS_YR, dann der Rest
clean_dat_motor <- clean_dat_motor %>%
  dplyr::select(OBJECT_ID, START_INS_YR, SEX, INSR_TYPE, USAGE, TYPE_VEHICLE,
                MAKE, AGE_VEHICLE, SEATS_NUM, CCM_TON, INSURED_VALUE, PREMIUM, CLAIM_PAID_USD, everything())

#Data set too large: Draw 100000 random samples
clean_dat_motor_origin<- clean_dat_motor
clean_dat_motor <- sample_n(clean_dat_motor, size = 100000)


#Umwandlung der kategorialen Variablen in Factor-Variablen
clean_dat_motor$OBJECT_ID <- as.factor(clean_dat_motor$OBJECT_ID)
clean_dat_motor$SEX <- as.factor(clean_dat_motor$SEX)
clean_dat_motor$INSR_TYPE <- as.character(clean_dat_motor$INSR_TYPE)
clean_dat_motor$INSR_TYPE <- as.factor(clean_dat_motor$INSR_TYPE)
clean_dat_motor$MAKE <- as.factor(clean_dat_motor$MAKE)
clean_dat_motor$USAGE <- as.factor(clean_dat_motor$USAGE)
clean_dat_motor$CLAIM_PAID <- as.factor(clean_dat_motor$CLAIM_PAID)
clean_dat_motor$TYPE_VEHICLE <- as.factor(clean_dat_motor$TYPE_VEHICLE)
clean_dat_motor$START_INS_YR <- as.factor(clean_dat_motor$START_INS_YR)


# Clear Workspace
rm(list = setdiff(ls(), c("clean_dat_motor_origin", "clean_dat_motor")))
#rm(clean_dat_motor_origin)


```



# Graphical Data Analysis

```{r graph_data_analysis, cache = TRUE}

# Auswahl nur der numerischen Variablen
numeric_vars <- clean_dat_motor %>%
  select_if(is.numeric)

# Erstellen von Histogrammen für jede numerische Variable
for (var in names(numeric_vars)) {
  print(
    ggplot(clean_dat_motor, aes_string(x = var)) +
      geom_histogram(bins = 30, color = "black", fill = "skyblue") +
      ggtitle(paste("Histogram of", var)) +
      theme_minimal() +
      xlab(var) +
      ylab("Frequency") +
      theme(plot.title = element_text(hjust = 0.5))
  )
}


###################################################################################

#Weitere grafische Analysen
boxplot(PREMIUM ~ SEX, data = clean_dat_motor,
main = "Premium against sex",
ylab = "Premium")

boxplot(CLAIM_PAID_USD ~ SEX, data = clean_dat_motor,
main = "Claim paid (USD) against sex",
ylab = "Claim paid (USD)")

```



## Transformation variables 
```{r transformation, cache = TRUE}

#Log-Transformation
clean_dat_motor$INSURED_VALUE_log <- log(clean_dat_motor$INSURED_VALUE)
clean_dat_motor$PREMIUM_log <- log(clean_dat_motor$PREMIUM)
#Log-Transformation mit log1p() wegen der vielen 0-Werte
clean_dat_motor$CLAIM_PAID_USD_log <- log1p(clean_dat_motor$CLAIM_PAID_USD)
clean_dat_motor$CCM_TON_LOG <- log1p(clean_dat_motor$CCM_TON)

```



# Models
## Linear Model

```{r linear_model, cache = TRUE}

#Modell erstellen
lm_model <- lm(PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + INSURED_VALUE + CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + CCM_TON, data = clean_dat_motor)

#Modellzusammenfassung anzeigen
summary(lm_model)
coef(lm_model)

Anova(lm_model, type="II")  # Type II oder III je nach Modellstrukt


vif(lm_model)


# Residuen plotten
plot(lm_model, which=1)  # Residuals vs Fitted
plot(lm_model, which=2)  # Normal Q-Q



#Residuen-Plots für Modell-Diagnose
#Plot der Residuen vs. Fit-Werte
plot(lm_model$fitted.values, lm_model$residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

#QQ-Plot der Residuen (Überprüfung der Normalverteilung)
qqnorm(lm_model$residuals, main = "QQ Plot of Residuals")
qqline(lm_model$residuals, col = "red")


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model) angezeigt)
r_squared <- summary(lm_model)$r.squared
cat("R-squared:", r_squared, "\n")

```


- R-squared= 0,6368, dh. 63,68% der Varianz in der Zielvariablen PREMIUM wird durch die erklärenden Variablen erklärt. Gut, hat aber Verbesserungspotential

- Alle Prädiktoren sind signifikant Pr(>F) <0,05

- Die Estimate-Werte zeigen die Richtung und Stärke des Effekts der jeweiligen Variable auf die PREMIUM
- INSR_TYPEPrivate hat tiefere Premium wie commercial
- Make: Die Marke Toyota hat die teuerste Praemie. Die guenstigste Premium hat die Marke HOWO
- Guenstigsten USAGEOwn Goods teuerste Premium Car Hires 
- teuerste Premium Type: Bus und guenstigsten Trailers and semitrailers
- Insured value und CLAIM_PAID_USD positiver effekt auf premium war zu erwarten


VIF:
Die VIF-Werte (Variance Inflation Factor) geben an, wie stark die Multikollinearität in deinem Modell ist. Hohe VIF-Werte (normalerweise über 5 oder 10) deuten darauf hin, dass einige Prädiktoren stark miteinander korrelieren, was die Stabilität und Interpretierbarkeit des Modells beeinträchtigen kann.
- INSR_TYPE (5.85): Ein VIF-Wert von über 5 deutet auf eine mögliche Multikollinearität hin. Es könnte sinnvoll sein, diese Variable genauer zu untersuchen.

Residuen
Der Residuals vs Fitted-Plot sollte keine Muster aufweisen (d.h. die Residuen sollten zufällig verteilt sein), und der Normal Q-Q-Plot sollte annähernd eine Gerade bilden, um die Normalverteilung der Residuen zu bestätigen.

Der Residuals vs Fitted Plot zeigt eine leicht gebogene Linie sowie eine Ansammlung von Punkten nahe dem Wert 0, begleitet von einigen extremen Ausreissern (mit ID-Nummern markiert). Dieses Muster deutet darauf hin, dass die Annahme der Homoskedastizität, also der gleichmässigen Varianz der Residuen, in diesem Modell nicht erfüllt ist. In einem idealen Modell sollten die Residuen zufällig und gleichmässig um die horizontale Linie bei 0 verteilt sein. Darüber hinaus sind einige Residuen-Punkte deutlich vom Hauptcluster entfernt. Diese Ausreisser könnten extreme Werte darstellen, die das Modell möglicherweise verzerren. Eine genauere Untersuchung dieser Punkte ist empfehlenswert, um zu entscheiden, ob sie aus dem Modell entfernt oder separat behandelt werden sollten. Bei höheren Prämienwerten zeigen die Residuen zudem eine ungleichmässige Verteilung, was darauf hindeutet, dass das Modell für diese höheren Werte keine ausreichende Passgenauigkeit aufweist.

Im Normal Q-Q Plot lässt sich erkennen, dass die Residuen nicht vollständig auf der Linie liegen, die eine perfekte Normalverteilung darstellt. Dies weist darauf hin, dass die Annahme der Normalverteilung der Residuen verletzt ist. Besonders auffällig sind die deutlichen Abweichungen sowohl am unteren als auch am oberen Ende des Plots. Dies deutet auf das Vorhandensein von Ausreissern hin und darauf, dass die Verteilung der Residuen „schwerere Enden“ aufweist, d. h. mehr extreme Werte enthält als in einer Normalverteilung zu erwarten wäre. Die Punkte am Rand des Plots repräsentieren extreme Werte, die signifikant von der angenommenen Normalverteilung abweichen.

Massnahmen:Transformation der Zielvariablen, Ausreisserbehandlung



### Massnahme 1): Ausreisserbehandlung

```{r lm_massnahme_ausreisser, cache=TRUE}

# Standardisierte Residuen berechnen
standardized_resid <- rstandard(lm_model)

# Schwellenwert für Ausreisser setzen (z.B. Residuen grösser als 3 oder kleiner als -3)
threshold <- 3

# Indizes der Ausreisser identifizieren
outliers <- which(abs(standardized_resid) > threshold)

# Daten ohne Ausreisser
clean_data_no_outliers <- clean_dat_motor[-outliers, ]

# Neues Modell ohne Ausreisser anpassen
lm_model_no_outliers <- lm(PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + INSURED_VALUE + CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + CCM_TON, data = clean_data_no_outliers)

# Zusammenfassung des neuen Modells anzeigen
summary(lm_model_no_outliers)

# Residuenplots für das neue Modell erstellen
par(mfrow = c(2, 2))  # Mehrere Plots auf einer Seite
plot(lm_model_no_outliers)




```

Nach dem Entfernen der Ausreisser zeigen die Residuenplots zwar eine Verbesserung, jedoch bleiben einige Auffälligkeiten bestehen. Der Residuals vs Fitted Plot weist weiterhin eine Trichterform auf, was auf eine Verletzung der Homoskedastizitätsannahme hindeutet. Dies deutet darauf hin, dass die Varianz der Residuen nicht konstant ist. Im Normal Q-Q Plot sind an den Enden deutliche Abweichungen von der theoretischen Normalverteilung zu erkennen, was auf verbleibende Ausreisser oder eine unzureichende Anpassung an die Normalverteilungsannahme schliessen lässt. Der Scale-Location Plot bestätigt ebenfalls eine ungleichmässige Streuung der Residuen, insbesondere bei höheren fitted values. Insgesamt legen diese Ergebnisse nahe, dass eine Transformation der Zielvariablen, wie eine Log-Transformation, sinnvoll sein könnte, um die Modellgüte weiter zu verbessern und die Annahmen der linearen Regression besser zu erfüllen.

Die Modellgüte hat sich verbessert: Der Residual Standard Error (RSE) verringerte sich von über 7700 auf 6168, und das R-squared stieg von 0,6368 auf 0,7175. Dies bedeutet, dass nun 71,75% der Varianz in der Prämie durch die erklärenden Variablen erklärt werden. Die meisten Variablen, wie INSURED_VALUE und CLAIM_PAID_USD, bleiben weiterhin signifikant.



### Massnahme 2): Transformation

```{r lm_massnahme_transf, cache=TRUE}

#Analyse Variablen
numeric_vars <- c("PREMIUM", "INSURED_VALUE", "CLAIM_PAID_USD", "AGE_VEHICLE", "SEATS_NUM", "CCM_TON")

#Histogramme erstellen
par(mfrow = c(2, 3))  # 2 Zeilen, 3 Spalten für die Plots
for (var in numeric_vars) {
  hist(clean_dat_motor[[var]], main = paste("Histogram of", var), xlab = var, col = "lightblue", breaks = 30)
}
par(mfrow = c(1, 1))  # Zurück zu einem einzelnen Plot pro Seite

#Massnahme: Transformation der Variablen
# Log-Transformation für stark rechtsschiefe Variablen
clean_dat_motor$PREMIUM_LOG <- log(clean_dat_motor$PREMIUM + 1)  # Hinzufügen von +1 um log(0) zu vermeiden
clean_dat_motor$INSURED_VALUE_LOG <- log(clean_dat_motor$INSURED_VALUE + 1)
clean_dat_motor$CLAIM_PAID_USD_LOG <- log(clean_dat_motor$CLAIM_PAID_USD + 1)
clean_dat_motor$CCM_TON_LOG <- log(clean_dat_motor$CCM_TON + 1)


```

Die Histogramme der Variablen zeigen, dass einige von ihnen, insbesondere PREMIUM, INSURED_VALUE, CLAIM_PAID_USD und CCM_TON, stark rechtsschief verteilt sind. Diese Verteilungen deuten darauf hin, dass eine log-Transformation sinnvoll sein könnte, um die Daten zu normalisieren und die Varianz zu stabilisieren. Durch die Transformation würde die Schiefe verringert, was zu einer besseren Modellanpassung führen könnte.

Variablen wie AGE_VEHICLE und SEATS_NUM zeigen hingegen eine weniger ausgeprägte Schiefe, sodass eine Transformation hier weniger notwendig erscheint. Eine log-Transformation der stark schiefen Variablen wird daher empfohlen, um die Modellgüte weiter zu verbessern.



```{r lm logtrans}

# Zunächst prüfen, ob es 0-Werte gibt, die das Logarithmieren verhindern
# Kleine Konstante (1) hinzufügen, um mit möglichen 0-Werten in den Variablen umzugehen
clean_data_no_outliers$LOG_PREMIUM <- log(clean_data_no_outliers$PREMIUM + 1)
clean_data_no_outliers$LOG_INSURED_VALUE <- log(clean_data_no_outliers$INSURED_VALUE + 1)
clean_data_no_outliers$LOG_CLAIM_PAID_USD <- log(clean_data_no_outliers$CLAIM_PAID_USD + 1)
clean_data_no_outliers$LOG_CCM_TON <- log(clean_data_no_outliers$CCM_TON + 1)

# Neues Modell mit den logarithmierten Variablen
lm_model_log <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                              LOG_INSURED_VALUE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + LOG_CCM_TON, 
                              data = clean_data_no_outliers)

# Zusammenfassung des neuen Modells anzeigen
summary(lm_model_log)
Anova(lm_model_log, type="II")  # Type II oder III je nach Modellstrukt

# Residuenplots für das neue Modell erstellen
par(mfrow = c(2, 2))  # Mehrere Plots auf einer Seite
plot(lm_model_log)


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model_log$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model_log) angezeigt)
r_squared <- summary(lm_model_log)$r.squared
cat("R-squared:", r_squared, "\n")

```



### Massnahme 3):  Ausreisser entfernen mit cooks distance

```{r lm_Ausreisser_log, cache=TRUE}

# Berechnung von Cook's Distance für das Modell
cooksd <- cooks.distance(lm_model_log)

# Setze einen Schwellenwert, um Ausreisser zu identifizieren (z.B. 4/n, wobei n die Anzahl der Datenpunkte ist)
threshold <- 4 / nrow(clean_data_no_outliers)

# Identifiziere potenziell einflussreiche Punkte (die Cook's Distance über dem Schwellenwert haben)
influential <- as.numeric(names(cooksd)[(cooksd > threshold)])

# Daten ohne diese einflussreichen Punkte
clean_data_no_outliers_influential_removed <- clean_data_no_outliers[-influential, ]

# Erstelle das Modell erneut ohne die einflussreichen Ausreisser
lm_model_no_influential <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                             LOG_INSURED_VALUE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + LOG_CCM_TON, 
                             data = clean_data_no_outliers_influential_removed)

# Zusammenfassung des neuen Modells
summary(lm_model_no_influential)

# Residuenplots für das neue Modell
par(mfrow = c(2, 2))
plot(lm_model_no_influential)


```

Nach dem Entfernen der einflussreichen Ausreisser zeigt das Modell eine deutliche Verbesserung. Die Residuen im Residuals vs Fitted Plot sind gleichmässiger um die Nulllinie verteilt, was auf eine verbesserte Homoskedastizität hinweist. Der Normal Q-Q Plot zeigt eine gute Annäherung an die Normalverteilung, mit nur geringen Abweichungen an den Enden. Der Scale-Location Plot bestätigt eine weitgehend konstante Varianz der Residuen, während im Residuals vs Leverage Plot nur wenige einflussreiche Datenpunkte verbleiben. Mit einem R-squared von 0,8028 erklärt das Modell nun 80,28% der Varianz, was eine signifikante Verbesserung darstellt.

### Massnahme 4):  Interaktionen? noch nicht fix

```{r lm_interaktion, cache=TRUE}

# Boxplot von LOG_PREMIUM nach MAKE und USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=MAKE, y=LOG_PREMIUM, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen MAKE und USAGE", x = "MAKE", y = "LOG_PREMIUM")

# Boxplot von LOG_PREMIUM nach TYPE_VEHICLE und USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=TYPE_VEHICLE, y=LOG_PREMIUM, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen TYPE_VEHICLE und USAGE", x = "TYPE_VEHICLE", y = "LOG_PREMIUM")

# Scatterplot von LOG_INSURED_VALUE und LOG_PREMIUM nach USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=LOG_INSURED_VALUE, y=LOG_PREMIUM, color=USAGE)) + 
  geom_point(alpha=0.5) + 
  geom_smooth(method="lm", se=FALSE) +
  labs(title = "Interaktion zwischen LOG_INSURED_VALUE und USAGE", x = "LOG_INSURED_VALUE", y = "LOG_PREMIUM")



# Anpassung eines linearen Modells mit den identifizierten Interaktionen
lm_model_interactions <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE * USAGE + TYPE_VEHICLE * USAGE + 
                            LOG_INSURED_VALUE * USAGE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + 
                            LOG_CCM_TON, data = clean_data_no_outliers_influential_removed)

# Zusammenfassung des neuen Modells mit Interaktionen
summary(lm_model_interactions)

# Residuenplots für das neue Modell
par(mfrow = c(2, 2))
plot(lm_model_interactions)



```

Obwohl die Hinzufügung von Interaktionen das Modell in einigen Aspekten verbessert hat, zeigen die Residuenanalysen, dass Heteroskedastizität und Ausreisser weiterhin Probleme darstellen. Mögliche nächste Schritte könnten die Überprüfung und Behandlung dieser einflussreichen Punkte sowie die Anwendung robusterer Regressionstechniken oder zusätzlicher Transformationen umfassen. Darüber hinaus könnte die Untersuchung weiterer Interaktionen oder die Modellierung nichtlinearer Effekte in Betracht gezogen werden, um die Anpassung weiter zu optimieren.


## Poisson

```{r Poisson_Model, cache=TRUE}

#Data preparation: Aggregate the number of claims per combination of vehicle type, insurance type, and production year
dat_amount_claims <- clean_dat_motor %>%
  group_by(SEX, TYPE_VEHICLE, INSR_TYPE, MAKE, AGE_VEHICLE, SEATS_NUM) %>%
  summarise(Amount_Claims = sum(CLAIM_PAID == "YES"), .groups = 'drop')

hist(dat_amount_claims$Amount_Claims, breaks=100)

mean(dat_amount_claims$Amount_Claims) # calculate mean
var(dat_amount_claims$Amount_Claims)
#The variance is much greater than the mean, which suggests that we will have over-dispersion in the model.

#Poisson Regression:
poisson_model<- glm(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + MAKE + AGE_VEHICLE + SEATS_NUM, 
                      family = poisson(link = "log"), data = dat_amount_claims)

#Summary of the model
summary(poisson_model)

#Coeff
coef(poisson_model)
exp(coef(poisson_model))

# Model diagnostics and evaluation
# Residuals vs. Fitted Plot
plot(poisson_model$fitted.values, residuals(poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# QQ Plot of residuals (Check for normal distribution)
qqnorm(residuals(poisson_model, type = "deviance"), main = "QQ Plot of Residuals")
qqline(residuals(poisson_model, type = "deviance"), col = "red")

#Diagnose overdispersion
deviance(poisson_model) / df.residual(poisson_model)


```
The residuals vs. fitted diagram shows an increasing dispersion of the residuals with increasing estimated values, which indicates heteroscedasticity. This indicates that the variance of the residuals is not constant and supports the assumption of overdispersion, as the variance is significantly greater than the mean. The QQ plot of the residuals shows a strong deviation from the theoretical normal distribution, especially at the ends, which indicates a lack of normal distribution of the residuals. This deviation is typical for Poisson models, but the significant differences indicate overdispersion or possibly missing predictors. The calculation of the ratio of deviance to degrees of freedom (11.86) confirms the overdispersion, as this value is significantly greater than 1 and thus indicates a higher variance in the data than assumed in the Poisson model.

The significance of the predictors in the model becomes clear from the p-values of the coefficient estimates. Almost all predictors show extremely low p-values (p < 0.001), which indicates that they have a significant influence on the number of claims. This high significance strengthens the significance of the correlations found. Nevertheless, the overdispersion remains problematic, as it indicates that the Poisson model may underestimate the variance in the data. Despite the statistical significance of the predictors, a model change, e.g. to a quassi Poisson model or a negative binomial model, could be necessary to improve the model quality and to address the overdispersion appropriately.


### Massnahme 1): Quasi-Poisson-Regression

```{r quasiPois, cache=TRUE}

#Quasi-Poisson
quasi_poisson_model <- glm(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + MAKE + AGE_VEHICLE + SEATS_NUM, 
                           family = quasipoisson, data = dat_amount_claims)

# Summary of the model
summary(quasi_poisson_model)
#F-Test, Vergleiche von geschachtelten Quasi-Likelihood-Modellen (Overdispersion)
drop1(quasi_poisson_model, test= "F")

# Model diagnostics: Residuals vs. Fitted Plot
plot(quasi_poisson_model$fitted.values, residuals(quasi_poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Quasi-Poisson)")
abline(h = 0, col = "red")

# QQ plot of residuals (checking normality)
qqnorm(residuals(quasi_poisson_model, type = "deviance"), main = "QQ Plot of Residuals (Quasi-Poisson)")
qqline(residuals(quasi_poisson_model, type = "deviance"), col = "red")



```
Switching to a quasi-Poisson model to account for overdispersion led to improvements compared to the original Poisson model. The residuals vs. fitted plot shows a reduced dispersion of the residuals at higher estimated values, which indicates a better fit of the variance, although heteroscedasticity still exists. The QQ plot of the residuals shows an improved fit to the theoretical normal distribution, especially in the middle range, while deviations at the edges remain, indicating extreme values or modelling errors. By adjusting the dispersion parameter (29.765) in the quasi-Poisson model, the increased variance compared to the Poisson model is adequately taken into account. The F-test confirms the significance of the variables ‘SEX’, ‘TYPE_VEHICLE’, ‘MAKE’, ‘AGE_VEHICLE’ and ‘SEATS_NUM’. Despite these improvements, there are still slight anomalies in the residuals.

### Massnahme 2): Negative-Binomial-Modell

```{r neg_binom_model, cache=TRUE}

# Negative-Binomial-Regression anpassen
neg_bin_model <- glm.nb(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + MAKE + AGE_VEHICLE + SEATS_NUM,
                        data = dat_amount_claims)

# Zusammenfassung des Modells anzeigen
summary(neg_bin_model)
drop1(neg_bin_model, test= "LRT")

# Exponentierte Koeffizienten anzeigen (um Rate Ratios zu interpretieren)
exp(coef(neg_bin_model))

# Konfidenzintervalle für die Koeffizienten
confint(neg_bin_model)


# Devianz und Freiheitsgrade überprüfen (sollte näher an 1 liegen)
deviance(neg_bin_model) / df.residual(neg_bin_model)

# Residuals vs Fitted Plot
plot(neg_bin_model$fitted.values, residuals(neg_bin_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Negative Binomial)")
abline(h = 0, col = "red")

# QQ-Plot der Residuen
qqnorm(residuals(neg_bin_model, type = "deviance"), main = "QQ Plot of Residuals (Negative Binomial)")
qqline(residuals(neg_bin_model, type = "deviance"), col = "red")

```

The fitting of a negative binomial model shows significant improvements compared to the previous models. The residuals vs fitted plot indicates that the residuals are better distributed overall, especially at larger values of the fitted data, with lower heteroscedasticity. However, the QQ plot of the residuals still shows slight deviations from the normal distribution, especially at the extreme values, which indicates remaining modelling anomalies.

The model shows a significant improvement in terms of overdispersion, as suggested by the ratio of deviance to degrees of freedom (0.822), which is closer to 1 and thus significantly reduces overdispersion. Most predictors continue to show high levels of significance, indicating a strong explanatory power for the number of claims.


## Binomial
```{r Binomial_Model, cache=TRUE}

#Erstellen eines logistischen Regressionsmodells
fit.binom <- glm(CLAIM_PAID ~ SEX + INSR_TYPE + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
             MAKE + SEATS_NUM + CCM_TON + USAGE, 
             data = clean_dat_motor, 
             family = binomial)

# Zusammenfassung des Modells anzeigen
summary(fit.binom)
drop1(fit.binom, test= "LRT")

```

INSR_TYPE and CCM_Ton do not appear to be significant. A new model is adapted without these two variables.

```{r Binomial_Model_sign, cache=TRUE}

#Erstellen eines logistischen Regressionsmodells
fit.binom2 <- glm(CLAIM_PAID ~ SEX +  INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
             MAKE + SEATS_NUM + USAGE, 
             data = clean_dat_motor, 
             family = binomial)

# Zusammenfassung des Modells anzeigen
summary(fit.binom2)
drop1(fit.binom2, test= "LRT")

# Wahrscheinlichkeiten vorhersagen
clean_dat_motor$predicted_probabilities <- predict(fit.binom2, type = "response")

# Klassifikation vorhersagen (0 oder 1)
clean_dat_motor$predicted_class <- ifelse(clean_dat_motor$predicted_probabilities > 0.5, 1, 0)

# Modellgüte prüfen
table(clean_dat_motor$CLAIM_PAID, clean_dat_motor$predicted_class)

# Optional: Genauigkeit berechnen
accuracy <- mean(clean_dat_motor$CLAIM_PAID == clean_dat_motor$predicted_class)
print(paste("Genauigkeit des Modells:", accuracy))

```

Schlechte Modellgüte

### Massnahme 1): Down-Sampling (Balancing) und weniger Variablen

```{r binom_balanced, cache=TRUE}
# Anzahl der YES-Klasse ermitteln
yes_class <- clean_dat_motor[clean_dat_motor$CLAIM_PAID == "YES", ]
no_class <- clean_dat_motor[clean_dat_motor$CLAIM_PAID == "NO", ]

# Anzahl der YES-Beobachtungen
n_yes <- nrow(yes_class)

# Zufällige Auswahl aus der NO-Klasse, sodass sie die gleiche Größe wie die YES-Klasse hat
set.seed(42)  # Für Reproduzierbarkeit
no_class_undersampled <- no_class[sample(1:nrow(no_class), n_yes), ]

# Erstellen eines neuen Datensatzes, der YES und die undersampelte NO-Klasse kombiniert
clean_dat_motor_undersampled <- rbind(yes_class, no_class_undersampled)

# Überprüfen der neuen Klassenverteilung
table(clean_dat_motor_undersampled$CLAIM_PAID)

# Logistisches Regressionsmodell mit undersampelten Daten
fit.binom_undersampled <- glm(CLAIM_PAID ~ SEX + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
                             MAKE + SEATS_NUM + USAGE, 
                             data = clean_dat_motor_undersampled, 
                             family = binomial)

# Zusammenfassung des neuen Modells
summary(fit.binom_undersampled)
drop1(fit.binom_undersampled, test= "LRT") #SEATS_NUM not sign





# Logistisches Regressionsmodell mit undersampelten Daten
fit.binom_undersampled2 <- glm(CLAIM_PAID ~ SEX + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
                             MAKE + USAGE, data = clean_dat_motor_undersampled, 
                             family = binomial)

# Zusammenfassung des neuen Modells
summary(fit.binom_undersampled2)
drop1(fit.binom_undersampled2, test= "LRT")

# Wahrscheinlichkeiten vorhersagen
clean_dat_motor_undersampled$predicted_probabilities <- predict(fit.binom_undersampled2, type = "response")

# Klassifikation vorhersagen (0 oder 1)
clean_dat_motor_undersampled$predicted_class <- ifelse(clean_dat_motor_undersampled$predicted_probabilities > 0.5, 1, 0)

# Modellgüte prüfen
table(clean_dat_motor_undersampled$CLAIM_PAID, clean_dat_motor_undersampled$predicted_class)

# Genauigkeit berechnen
accuracy_undersampled <- mean(clean_dat_motor_undersampled$CLAIM_PAID == clean_dat_motor_undersampled$predicted_class)
print(paste("Genauigkeit des undersampelten Modells:", accuracy_undersampled))




# Umwandlung in Faktoren für die Auswertung
predicted_class <- as.factor(clean_dat_motor_undersampled$predicted_class)
actual_class <- as.factor(clean_dat_motor_undersampled$CLAIM_PAID)


# Sicherstellen, dass predicted_class und actual_class die gleichen Levels haben
levels(predicted_class) <- levels(actual_class)

# Levels überprüfen
levels(predicted_class)
levels(actual_class)

# Berechnung der Metriken
confusionMatrix(predicted_class, actual_class)


```

weitere Massnahmen: Schwellenwertanpassubg (hat wenig gebracht) Interaktionen
## Generalised Additive Model (GAM)
```{r GAM, cache=TRUE}
# TODO

```

## Neural Network
```{r Neural_Network, cache=TRUE}
# TODO

```


## Support Vector Machine (SVM)
```{r SVM preparation}
set.seed(123)
svm_data <- clean_dat_motor[sample(nrow(clean_dat_motor), 100000, replace = FALSE), ]

hist(svm_data$PREMIUM_LOG, main = "Premium Distribution", xlab = "Premium", breaks = 30)

plot(density(svm_data$PREMIUM_LOG, na.rm = TRUE), main = "Density of Premium")

percentiles <- quantile(svm_data$PREMIUM_LOG, probs = c(0.25,0.5,0.75))

# Create custom categories for PREMIUM based on percentiles
svm_data$premium_category <- cut(svm_data$PREMIUM_LOG, 
                                 breaks = c(-Inf, percentiles[1], percentiles[2], percentiles[3], Inf), 
                                 labels = c("low", "medium", "high", "very_high"))
print(table(svm_data$premium_category
            ))

# Splitting into training and testing test
trainIndex <- createDataPartition(svm_data$premium_category, p = 0.7, list = FALSE)
train <- svm_data[trainIndex, ]
test <- svm_data[-trainIndex, ]

#plotting to see if it can be linearly split

selected_data <- svm_data[, c("AGE_VEHICLE", "INSURED_VALUE_LOG", "CLAIM_PAID_USD_LOG", "premium_category")]
library(GGally)
ggpairs(selected_data, aes(color = premium_category))
```

Given the overlaps and distribution of data points across different categories, the data does not appear to be linearly separable. This means that a non-linear kernel would likely be a better choice for capturing the complex relationships and boundaries between the classes.

```{r SVM radial, cache=TRUE}

fit <- svm(premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, 
             data = train, 
             kernel = "radial")

summary(fit)

predictions <- predict(fit, test)
confusionMatrix(predictions, test$premium_category)

```
Performance Analysis
Overall Accuracy:

Accuracy: 71.62% is still a solid performance for a four-class classification task but is slightly lower than before (72.24%). This drop could be due to sample variation, indicating the model may be sensitive to the specific data distribution in the training set.
Class-Specific Performance:

Class Sensitivity:
The model performs best in identifying the “very high” class (Sensitivity = 0.8545), meaning it effectively detects most "very high" premium cases.
The “low” (67.35%) and “high” (67.89%) classes show lower sensitivities, which implies that the model struggles to identify these categories as accurately. Misclassifications here likely contribute to the reduced accuracy.
Specificity: High specificity across all classes, particularly for “low” (96.30%) and “very high” (91.17%), suggests the model effectively recognizes cases that do not belong to these categories.
Positive Predictive Value (Precision):
Precision is reasonable across classes but lowest for “high” (60.51%) and “medium” (67.54%), indicating that the model may confuse these categories with others.
Balanced Accuracy:

Balanced accuracy is lower for "medium" (77.63%) and "high" (76.57%) compared to "low" and "very high." This imbalance suggests the model is slightly less effective in distinguishing between “medium” and “high” categories.
Recommendations for Improvement
Given the above observations, here are several suggestions to improve model performance:

Hyperparameter Tuning:

Increase Cost: Since the model has moderate sensitivity for “low” and “high” classes, increasing the cost parameter could encourage a tighter fit to these categories, potentially reducing the number of misclassifications. However, be cautious not to set it too high, as this could overfit on the “very high” class.
Gamma Tuning: Experiment with slightly higher values of gamma to see if it improves precision in "medium" and "high" classes. This could make the model more responsive to feature distinctions within these overlapping categories.

Alternative Kernel Exploration:

Polynomial Kernel: For cases where there is complex overlap between classes (e.g., "medium" and "high"), the polynomial kernel can sometimes capture these relationships better than the radial kernel.
Sigmoid Kernel: If the data has a certain linear-separability structure, experimenting with the sigmoid kernel could also improve classification.
Feature Engineering:

Interaction Terms: Create interaction terms between significant predictors, such as AGE_VEHICLE * INSURED_VALUE_LOG or CLAIM_PAID_USD_LOG * CCM_TON_LOG. These could help the model better distinguish between similar categories by capturing nuanced relationships.
Dimensionality Reduction: Try PCA (Principal Component Analysis) to reduce noise in the data. By retaining only the principal components that explain the most variance, you can simplify the feature space, potentially improving the model’s accuracy and generalization.
Class Rebalancing Techniques:

If there’s a slight imbalance in the data (e.g., fewer instances in "high" or "medium" categories), techniques like SMOTE (Synthetic Minority Over-sampling Technique) could help balance the classes, improving model performance on the lower-represented classes.
Try Ensemble Models for Comparison:

You may also consider training a Random Forest or Gradient Boosting model as a baseline to compare against SVM. These models can sometimes capture complex relationships and reduce misclassification for categories like "medium" and "high."


```{r SVM improvement from model#1}

# Perform hyperparameter tuning with tune()

# Define the formula with selected features

# Tune the model
tune.out <- tune(svm, premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, data = train, kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10),
                               gamma = c(0.5, 1, 2)))

# View the best parameters and summary
print(tune.out)
best_model <- tune.out$best.model

# Print the best cost and gamma values
best_params <- tune.out$best.parameters
cat("Best Cost:", best_params$cost, "\n")
cat("Best Gamma:", best_params$gamma, "\n")

# Fit the best model on the train data
fit.improved <- best_model


# library(caret)
# tune_grid <- expand.grid(C = c(1, 10, 100), gamma = c(0.01, 0.1, 1))
# tuned_model <- train(premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, 
#                      data = train, 
#                      method = "svmRadial", 
#                      tuneGrid = tune_grid, 
#                      trControl = trainControl(method = "cv"))

```
# Conclusion





