---
pdf_document: default
authors: "Alvaro Cervan, Luca Renz, Rafaella Miranda-Sousa"
date: "2024-01-10"
output:
  word_document: default
  pdf_document: default
title: "ML1"
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_packages, echo =FALSE, cache=TRUE}

#Install and import libraries.
if (!require("car")) install.packages("car")  # Support Vector Machine (SVM)
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("ROI")) install.packages("ROI")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("corrplot")) install.packages("corrplot")
if (!require("dplyr")) install.packages("dplyr")
if (!require("GGally")) install.packages("GGally")
if (!require("mgcv")) install.packages("mgcv")  # Generalised Additive Model (GAM)
if (!require("nnet")) install.packages("nnet")  # Neural Networks
if (!require("e1071")) install.packages("e1071")  # Support Vector Machine (SVM)
if (!require("MASS")) install.packages("MASS")
if (!require("arm")) install.packages("arm")

library(car)
library(readr,quietly = T)
library(ggplot2, quietly = T)
library(ROI, quietly = T)
library(tidyverse, quietly = T)
library(lubridate, quietly = T)
library(corrplot, quietly = T)
library(dplyr)
library(GGally)
library(mgcv)  # For Generalised Additive Models
library(nnet)  # For Neural Networks
library(e1071)  # For Support Vector Machine
library(arm)
library(caret)

```
Notizen Rafi
SVM Teil:
  Cross validation or other methods for model comparing must be used on one single
methods (e.g. you use Cross Validation to compare 2-3 SVM models).
• Students are free to choose a measure of fit that they find more appropriate.
• In case students cannot find an appropriate measure of fit, they can use the Root Mean
Squared Error (RMSE).

Schliesslich ist zu beachten, dass die Zusammenstellung von Dokumenten einige Zeit in Anspruch nehmen kann... insbesondere wenn komplexe
Modelle angepasst werden
- In diesen Fällen können Sie die Argumentationsoption cache = TRUE verwenden, so dass ein Chunk nur dann neu ausgewertet wird
nur dann neu ausgewertet wird, wenn er seit der letzten Kompilierung geändert wurde. Wenn der Chunk unverändert blieb
unverändert, dann werden die alten Ergebnisse verwendet



# Data Preprocessing

Aus Quelle:
  Some predictors such as carrying capacity and seat number are removed from the dataset prior
to data analysis and modeling since they are not correctly coded.


CHATGPT
CCM TON
Es macht keinen Sinn, dass Fahrzeuge einen Wert von 0 für die Variable CCM_TON haben, wenn diese Variable den Hubraum oder das Gewicht des Motors in Kubikzentimetern (ccm) oder Tonnen angibt.
Warum?
  Der Hubraum (ccm) gibt das Volumen der Zylinder eines Verbrennungsmotors an. Ein Wert von 0 wäre unplausibel, da ein Fahrzeug ohne Hubraum keinen funktionsfähigen Motor hätte.
Wenn CCM_TON das Gewicht des Motors in Tonnen angibt, wäre ebenfalls ein Wert von 0 unplausibel, da ein Fahrzeug ohne Motorgewicht nicht funktionsfähig wäre.

```{r data_prep, echo=FALSE, cache=TRUE}

# DATA LOAD
raw_dat_motor <- read_csv("data/motor_data14-2018.csv", show_col_types = FALSE)

dim(raw_dat_motor)
str(raw_dat_motor)

#DATA PREP

#EFFECTIVE_YR
#Entfernen der Spalte EFFECTIVE_YR (Hat keinen Nutzen, da nicht entziffert werden kann)
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "EFFECTIVE_YR")]

#CARRYING_CAPACITY
#Entfernen der Spalte CARRYING_CAPACITY
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "CARRYING_CAPACITY")]

#CLAIM_PAID
raw_dat_motor$CLAIM_PAID_USD <- ifelse(is.na(raw_dat_motor$CLAIM_PAID), 0, raw_dat_motor$CLAIM_PAID)
raw_dat_motor$CLAIM_PAID <- ifelse(raw_dat_motor$CLAIM_PAID_USD == 0, "NO", "YES")

# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

#SEX
raw_dat_motor$SEX <- factor(raw_dat_motor$SEX, 
                            levels = c(0, 1, 2), 
                            labels = c("Legal entity", "Male", "Female"))
table(raw_dat_motor$SEX)

#INSR_BEGIN
raw_dat_motor$INSR_BEGIN <- dmy(raw_dat_motor$INSR_BEGIN)

#INSR_END
raw_dat_motor$INSR_END <- dmy(raw_dat_motor$INSR_END)

#DURATION
raw_dat_motor$DURATION <- as.numeric(as.Date(raw_dat_motor$INSR_END) - as.Date(raw_dat_motor$INSR_BEGIN))
hist(raw_dat_motor$DURATION)
#Gleiche DURATION (Vertragsdauer) zur Vergleichbarkeit
raw_dat_motor <- raw_dat_motor[raw_dat_motor$DURATION == 364, ]

#Jahr des Versicherungsbeginns extrahieren und als neue Variable hinzufügen
raw_dat_motor$START_INS_YR <- year(as.Date(raw_dat_motor$INSR_BEGIN))

#INSR_TYPE
raw_dat_motor$INSR_TYPE <- factor(raw_dat_motor$INSR_TYPE, 
                                  levels = c(1201, 1202, 1204), 
                                  labels = c("Private", "Commercial", "Motor trade road risk"))

#INSURED_VALUE
#Überprüfen der Anzahl der fehlenden Werte
missing_values <- sum(is.na(raw_dat_motor$INSURED_VALUE))
cat("Fehlende Werte in INSURED_VALUE:", missing_values, "\n")

#Zusammenfassung der statistischen Kennzahlen
summary_stats <- summary(raw_dat_motor$INSURED_VALUE)
cat("Zusammenfassung der statistischen Kennzahlen von INSURED_VALUE:\n")
print(summary_stats)

#Ermittlung der Anzahl der Einträge, die 0 als Wert haben
zero_values <- sum(raw_dat_motor$INSURED_VALUE == 0, na.rm = TRUE)
cat("Anzahl der Einträge mit dem Wert 0 in INSURED_VALUE:", zero_values, "\n")

#Überprüfe, wie viele Datensätze betroffen sind
zero_insured_value <- raw_dat_motor[raw_dat_motor$INSURED_VALUE == 0, ]
cat("Anzahl der Datensätze mit INSURED_VALUE = 0:", nrow(zero_insured_value), "\n")

#Zusammenfassung der betroffenen Datensätze nach verschiedenen Variablen, um Muster zu erkennen
cat("Verteilung der Versicherungstypen (INSR_TYPE) bei INSURED_VALUE = 0:\n")
table(raw_dat_motor$INSR_TYPE) #Alle
print(table(zero_insured_value$INSR_TYPE)) #nur 0

cat("\nVerteilung der Fahrzeugtypen (TYPE_VEHICLE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$TYPE_VEHICLE))

cat("\nVerteilung der Fahrzeugnutzung (USAGE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$USAGE))

#Statistische Kennzahlen für andere Variablen bei INSURED_VALUE = 0 (z.B. PREMIUM)
cat("\nZusammenfassung der Prämien (PREMIUM) bei INSURED_VALUE = 0:\n")
summary(zero_insured_value$PREMIUM)

#Visualisierung der Fahrzeugnutzung bei INSURED_VALUE = 0
ggplot(zero_insured_value, aes(x = USAGE)) +
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Verteilung der Fahrzeugnutzung bei INSURED_VALUE = 0", x = "Fahrzeugnutzung", y = "Anzahl") +
  theme_minimal()

#Fazit: Es wurde kein Zusammenhang festgestellt. Vermutlich ist der Versicherungswert von 0 darauf zurückzuführen, dass gesetzlich nur eine Haftpflichtversicherung erforderlich ist. In diesen Fällen gibt es keinen festgelegten Wert für Schäden am Fahrzeug selbst. Daher werden Datensätze mit einem INSURED_VALUE von 0 aus der Analyse entfernt, da sie keine relevanten Informationen für die Bewertung von Fahrzeugwerten enthalten.

#Entfernen der Zeilen, bei denen INSURED_VALUE gleich 0 ist
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE != 0, ]

#Überprüfen, ob die Zeilen erfolgreich entfernt wurden
cat("Anzahl der verbleibenden Datensätze:", nrow(raw_dat_motor), "\n")

#Verteilung von INSURED_VALUE visualisieren (Histogramm)
ggplot(raw_dat_motor, aes(x = INSURED_VALUE)) +
  geom_histogram(binwidth = 50000, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Verteilung von INSURED_VALUE", x = "Versicherter Wert", y = "Häufigkeit") +
  theme_minimal()

#Boxplot zur Identifizierung von Ausreissern
ggplot(raw_dat_motor, aes(y = INSURED_VALUE)) +
  geom_boxplot(fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "Boxplot von INSURED_VALUE", y = "Versicherter Wert") +
  theme_minimal()

#Überprüfung der statistischen Kennzahlen ohne die 0-Werte
cat("Zusammenfassung der statistischen Kennzahlen ohne 0-Werte:\n")
print(summary(raw_dat_motor$INSURED_VALUE))

#Verteilung der log-transformierten INSURED_VALUE (nur für nicht-null Werte)
ggplot(raw_dat_motor[raw_dat_motor$INSURED_VALUE > 0, ], aes(x = log(INSURED_VALUE))) +
  geom_histogram(binwidth = 0.2, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Log-transformierte Verteilung von INSURED_VALUE (ohne Nullwerte)", x = "log(Versicherter Wert)", y = "Häufigkeit") +
  theme_minimal()

summary(raw_dat_motor$INSURED_VALUE)

#Ausreisser INSURED_VALUE entfernen 
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE >= 10, ]
summary(raw_dat_motor$INSURED_VALUE)

#Workspace
rm(zero_insured_value)

#PREMIUM
#Uberpruefung ob entfernen von PREMIUM = 0 vom Datensatz valide ist
data.frame(
  PREMIUM_0_Percent = round(100 * sum(raw_dat_motor$PREMIUM == 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_NA_Percent = round(100 * sum(is.na(raw_dat_motor$PREMIUM)) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_MORE_Percent = round(100 * sum(raw_dat_motor$PREMIUM > 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4)
)

#Entfernen der Zeilen, bei denen PREMIUM NA oder 0 ist
raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$PREMIUM) | raw_dat_motor$PREMIUM == 0), ]


# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

# OBJECT_ID
# Anzahl der Gesamtzeilen im Datensatz
total_rows <- nrow(raw_dat_motor)

# Anzahl der einzigartigen OBJECT_IDs
unique_object_ids <- length(unique(raw_dat_motor$OBJECT_ID))

# Überprüfen, ob OBJECT_IDs einmalig sind
if (total_rows == unique_object_ids) {
  cat("Die OBJECT_IDs sind einmalig.\n")
} else {
  cat("Die OBJECT_IDs sind NICHT einmalig.\n")
  cat("Anzahl der Duplikate:", total_rows - unique_object_ids, "\n")
  
  # Häufigkeit der OBJECT_IDs
  object_id_counts <- table(raw_dat_motor$OBJECT_ID)
  
  # Durchschnittliche und maximale Häufigkeit von OBJECT_ID
  avg_object_id_freq <- mean(object_id_counts)
  max_object_id_freq <- max(object_id_counts)
  
  cat("Durchschnittliche Häufigkeit der OBJECT_ID:", round(avg_object_id_freq, 3), "\n")
  cat("Maximale Häufigkeit der OBJECT_ID:", max_object_id_freq, "\n")
  
  # Häufigkeit der Kombination von OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE und PREMIUM
  combo_counts <- raw_dat_motor %>%
    group_by(OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM) %>%
    summarise(count = n(), .groups = 'drop')
  
  # Durchschnittliche und maximale Häufigkeit der Kombination
  avg_combo_freq <- mean(combo_counts$count) # Durchschnittliche Häufigkeit der Kombination
  max_combo_freq <- max(combo_counts$count)   # Maximale Häufigkeit der Kombination
  
  cat("Durchschnittliche Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", round(avg_combo_freq, 3), "\n")
  cat("Maximale Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", max_combo_freq, "\n")
}

#Teilweise gibt es bei CLAIM_PAID== YES eine vervielfachung
#Korrektur bzw. entfernen dieser mehrfachen Zeilen
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSR_TYPE, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  # Zähle die Anzahl der Zeilen in jeder Gruppe
  mutate(group_size = n()) %>%
  ungroup() %>%
  # Entferne Zeilen nur, wenn es eine Doppelzeile gibt und CLAIM_PAID == "NO" und CLAIM_PAID_USD <= 1
  filter(!(group_size > 1 & CLAIM_PAID == "NO" & CLAIM_PAID_USD <= 1)) %>%
  dplyr::select(-group_size)  # Entferne die Hilfsspalte

#Korrektur Wiederspruch bei INSR_TYPE
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  filter(!(n() > 1 & INSR_TYPE != "Commercial")) %>%  # Behalte nur die Zeilen mit "Commercial"
  ungroup()  # Ungroup, um das Gruppierungsobjekt zu entfernen

# Clear Workspace
rm(list = setdiff(ls(), "raw_dat_motor"))


#PROD_YEAR
#Zeilen mit PROD_YEAR NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$PROD_YEAR),]
summary(raw_dat_motor$PROD_YEAR)

#SEATS_NUM
#Analyse SEATS_NUM: Anzahl der Zeilen mit SEATS_NUM == 0, NA und anderen Werten
data.frame(
  SEATS_NUM_0 = sum(raw_dat_motor$SEATS_NUM == 0, na.rm = TRUE),
  SEATS_NUM_NA = sum(is.na(raw_dat_motor$SEATS_NUM)),
  SEATS_NUM_OTHER = sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE)
)
#Relativ: Prozentsatz der Zeilen mit SEATS_NUM == 0, NA oder anderen Werten
data.frame(
  SEATS_NUM_0_or_NA_Percent = 100 * sum(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0) / nrow(raw_dat_motor),
  SEATS_NUM_OTHER_Percent = 100 * sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE) / nrow(raw_dat_motor)
)
#Zeilen mit SEATS_NUM NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$SEATS_NUM),]
summary(raw_dat_motor$SEATS_NUM)

#Problematik: Es gibt SEATS_NUM mit 0

##Erstellen separater Datensätze für SEATS_NUM == 0 und SEATS_NUM > 0
#data_seats_num_0 <- subset(raw_dat_motor, SEATS_NUM == 0)
#data_seats_num_other <- subset(raw_dat_motor, SEATS_NUM > 0 & !is.na(SEATS_NUM))
## Tabellen der Fahrzeugtypen für beide Datensätze
#table(data_seats_num_0$TYPE_VEHICLE)
#table(data_seats_num_other$TYPE_VEHICLE)

##SEATS_NUM Alternative 1: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
##Liste der Fahrzeugtypen, bei denen SEATS_NUM == 0 unplausibel ist (Trailers and semitrailers, Tractor, Tanker werden gelassen)
#unplausible_types <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Station Wagones", "Tanker", "Truck")
##Entfernen der Zeilen, bei denen SEATS_NUM == 0 und der Fahrzeugtyp unplausibel ist
#raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$SEATS_NUM == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types), ]
#
#
##SEATS_NUM Alternative 2: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
#raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0), ]
#
##SEATS_NUM Alternative 3: Entfernen der SEATS_NUM-Spalte, da viele NA und schlechte Datenqualität
##raw_dat_motor <- subset(raw_dat_motor, select = -SEATS_NUM)

#TYPE_VEHICLE
#Entfernen der Zeilen, bei denen TYPE_VEHICLE == "Trade plates" Da zu wenige Auspraegungen (5)
#table(raw_dat_motor$TYPE_VEHICLE)
raw_dat_motor <- raw_dat_motor[raw_dat_motor$TYPE_VEHICLE != "Trade plates", ]

#CCM_TON
summary(raw_dat_motor$CCM_TON)
#Relativ CCM_TON 0
data.frame(
  CCM_TON_0_Percent = 100 * mean(raw_dat_motor$CCM_TON == 0, na.rm = TRUE),
  CCM_TON_MORE_Percent = 100 * mean(raw_dat_motor$CCM_TON > 0, na.rm = TRUE))
# Erstellen separater Datensätze für CCM_TON == 0 und CCM_TON > 0
data_CCM_TON_0 <- subset(raw_dat_motor, CCM_TON == 0)
data_CCM_TON_other <- subset(raw_dat_motor, CCM_TON > 0 & !is.na(CCM_TON))
# Tabellen der Fahrzeugtypen für beide Datensätze
table(data_CCM_TON_0$TYPE_VEHICLE)
table(data_CCM_TON_other$TYPE_VEHICLE)
# Liste der Fahrzeugtypen, bei denen CCM_TON == 0 unplausibel ist (Tractor,Trailers and semitrailers werden gelassen)
unplausible_types_ccm <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Truck", "Station Wagones", "Tanker", "Special construction")
# Entfernen der Zeilen, bei denen CCM_TON == 0 und der Fahrzeugtyp unplausibel ist
raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$CCM_TON == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types_ccm), ]


#USAGE
#table(raw_dat_motor$USAGE)
#Wenige Ausprägungen entfernen
raw_dat_motor <- subset(raw_dat_motor, !(USAGE %in% c("Fire fighting", "Learnes", "Others")))



#MAKE
#Zeilen mit MAKE NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$MAKE),]
#MAKE in Grossbuchstaben umwandeln
raw_dat_motor$MAKE <- toupper(raw_dat_motor$MAKE)

#Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
#Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")
# Behalten von Zeilen, in denen MAKE mit Buchstaben beginnt
raw_dat_motor <- raw_dat_motor[grepl("^[A-Za-z]", raw_dat_motor$MAKE), ]
table(raw_dat_motor$MAKE)


#Manuelle Korrekturen von MAKE
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PORCHE", "FORSCHE")] <- "PORSCHE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE == "YAMHA"] <- "YAMAHA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("VOLKSWAGON", "VOLKS WAGON")] <- "VOLKSWAGEN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("TOYOTAA", "TOYOTA*", "TOYTA", "TOYOTA AUTOMOBILE",
                                             "TOYATA", "T0Y0TA", "COMPACT YARIS", "YARIS",
                                             "LAND CRUISER", "VITZ")] <- "TOYOTA"
raw_dat_motor$MAKE[grepl("^TOYOTA", raw_dat_motor$MAKE)] <- "TOYOTA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("NISAN", "NISSAN*")] <- "NISSAN"
raw_dat_motor$MAKE[grepl("^NISSAN", raw_dat_motor$MAKE)] <- "NISSAN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENGE  ROVER", "RANGEROVER")] <- "RANGE ROVER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENALT", "RENUALT", "RENAULT/STOLARCZYK", "RENAULT*")] <- "RENAULT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PEUGEOUT", "PEJOT", "PAGOT")] <- "PEUGEOT"
raw_dat_motor$MAKE[grepl("^PEUGEOT", raw_dat_motor$MAKE)] <- "PEUGEOT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("BMB")] <- "BMW"
raw_dat_motor$MAKE[grepl("^BMW", raw_dat_motor$MAKE)] <- "BMW"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MISTIBUSH", "MITSUBISHI*", "MITSUBUSHI")] <- "MITSUBISHI"
raw_dat_motor$MAKE[grepl("^FORD", raw_dat_motor$MAKE)] <- "FORD"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SPORTAGE")] <- "KIA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MERCEEDES", "MERCEEDICE", "MERCEDICE", "MERCHEDES")] <- "MERCEDES"
raw_dat_motor$MAKE[grepl("^MERCEDES", raw_dat_motor$MAKE)] <- "MERCEDES"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SUZIKE")] <- "SUZUKI"
raw_dat_motor$MAKE[grepl("^SUZUKI", raw_dat_motor$MAKE)] <- "SUZUKI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HYUNDI GETZ")] <- "HYUNDAI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("ISUSU")] <- "ISUZU"
raw_dat_motor$MAKE[grepl("^ISUZU", raw_dat_motor$MAKE)] <- "ISUZU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("FRANKUN IVECO")] <- "IVECO"
raw_dat_motor$MAKE[grepl("^IVECO", raw_dat_motor$MAKE)] <- "IVECO"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LANDROVER")] <- "LAND ROVER"


raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DONGFANG", "DONFING", "DONG FENGSHEN", "DONG FENG")] <- "DONGFENG"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MAHANDRA")] <- "MAHINDRA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HOLAND CAR")] <- "ABAY"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("CALABRASE")] <- "CALABRESE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("GELYION", "GENLION", "GELION", "GENLYONIVECO", "HONGYAN")] <- "GENLYON"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DHATSU", "DIATSU", "DIAHATSU")] <- "DAIHATSU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DAWOO", "DAWWO", "DEAWOO", "DEAWOO USE")] <- "DAEWOO"
raw_dat_motor$MAKE[grepl("^LIFAN", raw_dat_motor$MAKE)] <- "LIFAN"
raw_dat_motor$MAKE[grepl("^BAIC", raw_dat_motor$MAKE)] <- "BAIC"
raw_dat_motor$MAKE[grepl("^LOADER", raw_dat_motor$MAKE)] <- "LOADER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MOTOR CYCLE", "MOTOR  CYCLE")] <- "MOTORCYCLE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("AUTO", "AUTOMOBIL")] <- "AUTOMOBILE"
raw_dat_motor$MAKE[grepl("^CATERPILLAR", raw_dat_motor$MAKE)] <- "CATERPILLAR"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LIBER DOZER", "LIBERR MOBILE CRANE",
                                             "LIEBERR MOBILE CRANE", "LEABER CATO CRANE",
                                             "LEBHER CRANE", "CRANE LEBEHER",
                                             "CRANE LEBHERER", "LIBER", "LIBEHER CRANE",
                                             "LIBERR MOBILECRANE", "CRANELEBHER")] <- "LIEBHERR"

#table(raw_dat_motor$MAKE)

#Zähle die Anzahl der Einträge pro MAKE, wo CLAIM_PAID == "YES"
count_claims_paid <- raw_dat_motor %>%
  group_by(MAKE, CLAIM_PAID ) %>%                 # Gruppiere nach MAKE
  summarise(count = n()) %>%        # Zähle die Einträge pro Gruppe
  arrange(desc(count)) 

###############################################################################################


#Liste der gewünschten Fahrzeughersteller (Make)
selected_makes <- c("TOYOTA", "ISUZU", "NISSAN", "IVECO", "SINO HOWO", 
                    "MITSUBISHI", "BISHOFTU", "LIFAN", "FORD", "HYUNDAI", 
                    "MAZDA", "GEELY", "DAEWOO", "MERCEDES", "TATA", 
                    "FIAT", "SINO", "SUZUKI", "GENLYON", "RENAULT")

#Filtern des Datensatzes nach den ausgewählten Fahrzeugherstellern
clean_dat_motor <- subset(raw_dat_motor, MAKE %in% selected_makes)

#Wenige Ausprägungen entfernen
#table(clean_dat_motor$SEX) #OK

#table(clean_dat_motor$USAGE)
clean_dat_motor <- subset(clean_dat_motor, !(USAGE %in% c("Agricultural Any Farm",
                                                          "Agricultural Own Farm",
                                                          "Special Construction", "Taxi")))

#table(clean_dat_motor$TYPE_VEHICLE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(TYPE_VEHICLE %in% c("Tractor")))

#table(clean_dat_motor$INSR_TYPE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(INSR_TYPE %in% c("Motor trade road risk")))

#table(clean_dat_motor$MAKE)

#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

#New Variable: age_vehicle
clean_dat_motor$AGE_VEHICLE <- 2018 - clean_dat_motor$PROD_YEAR
#Entfernen von PROD_YEAR
clean_dat_motor<- clean_dat_motor[,-8]



#New variable: AMOUNT_CLAIMS_PAID (Number of previous claims per object ID)
clean_dat_motor <- clean_dat_motor %>%
  # Für jede object_ID und jedes Startjahr, kumuliere die Anzahl vorheriger Claims mit "YES"
  group_by(OBJECT_ID) %>%
  arrange(OBJECT_ID, START_INS_YR) %>%
  mutate(
    AMOUNT_CLAIMS_PAID = sapply(seq_along(START_INS_YR), function(i) {
      sum(CLAIM_PAID[1:(i-1)] == "YES" & START_INS_YR[1:(i-1)] < START_INS_YR[i])
    })
  ) %>%
  ungroup()


###############################################################################################

#Vergleich zum Rohdatensatz
#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))


###############################################################################################

#NA
colSums(is.na(raw_dat_motor)) 
colSums(is.na(clean_dat_motor)) 

#Entfernen der Variablen 'versicherungsbeginn' und 'versicherungsende'
clean_dat_motor <- subset(clean_dat_motor, select = -c(INSR_BEGIN, INSR_END, DURATION))

# Neuanordnung der Spalten: Zuerst OBJECT_ID, dann START_INS_YR, dann der Rest
clean_dat_motor <- clean_dat_motor %>%
  dplyr::select(OBJECT_ID, START_INS_YR, SEX, INSR_TYPE, USAGE, TYPE_VEHICLE,
                MAKE, AGE_VEHICLE, SEATS_NUM, CCM_TON, INSURED_VALUE, PREMIUM, CLAIM_PAID_USD, everything())

#Data set too large: Draw 100000 random samples
clean_dat_motor_origin<- clean_dat_motor
set.seed(123)
clean_dat_motor <- sample_n(clean_dat_motor, size = 100000)


#Umwandlung der kategorialen Variablen in Factor-Variablen
clean_dat_motor$OBJECT_ID <- as.factor(clean_dat_motor$OBJECT_ID)
clean_dat_motor$SEX <- as.factor(clean_dat_motor$SEX)
clean_dat_motor$INSR_TYPE <- as.character(clean_dat_motor$INSR_TYPE)
clean_dat_motor$INSR_TYPE <- as.factor(clean_dat_motor$INSR_TYPE)
clean_dat_motor$MAKE <- as.factor(clean_dat_motor$MAKE)
clean_dat_motor$USAGE <- as.factor(clean_dat_motor$USAGE)
clean_dat_motor$CLAIM_PAID <- as.factor(clean_dat_motor$CLAIM_PAID)
clean_dat_motor$TYPE_VEHICLE <- as.factor(clean_dat_motor$TYPE_VEHICLE)
clean_dat_motor$START_INS_YR <- as.factor(clean_dat_motor$START_INS_YR)


# Clear Workspace
rm(list = setdiff(ls(), c("clean_dat_motor_origin", "clean_dat_motor")))
#rm(clean_dat_motor_origin)


```



# Graphical Data Analysis

```{r graph_data_analysis, cache = TRUE}

# Auswahl nur der numerischen Variablen
numeric_vars <- clean_dat_motor %>%
  select_if(is.numeric)

# Erstellen von Histogrammen für jede numerische Variable
for (var in names(numeric_vars)) {
  print(
    ggplot(clean_dat_motor, aes_string(x = var)) +
      geom_histogram(bins = 30, color = "black", fill = "skyblue") +
      ggtitle(paste("Histogram of", var)) +
      theme_minimal() +
      xlab(var) +
      ylab("Frequency") +
      theme(plot.title = element_text(hjust = 0.5))
  )
}


###################################################################################

#Weitere grafische Analysen
boxplot(PREMIUM ~ SEX, data = clean_dat_motor,
main = "Premium against sex",
ylab = "Premium")

boxplot(CLAIM_PAID_USD ~ SEX, data = clean_dat_motor,
main = "Claim paid (USD) against sex",
ylab = "Claim paid (USD)")

```



## Transformation variables 
```{r transformation, cache = TRUE}

#Log-Transformation
clean_dat_motor$INSURED_VALUE_log <- log(clean_dat_motor$INSURED_VALUE)
clean_dat_motor$PREMIUM_log <- log(clean_dat_motor$PREMIUM)
#Log-Transformation mit log1p() wegen der vielen 0-Werte
clean_dat_motor$CLAIM_PAID_USD_log <- log1p(clean_dat_motor$CLAIM_PAID_USD)
clean_dat_motor$CCM_TON_LOG <- log1p(clean_dat_motor$CCM_TON)


# Clear Workspace
rm(list = setdiff(ls(), c("clean_dat_motor_origin", "clean_dat_motor")))

```



# Models
## Linear Model

A linear model is adapted, whereby CLAIM_PAID_USD_log was not included, as the premium is incurred at the start of the contract and this would therefore not make technical sense. Instead, a bonus-malus system is taken into account by adding AMOUNT_CLAIMS_PAID.

```{r linear_model, cache = TRUE}

#Modell erstellen
lm_model <- lm(PREMIUM_log ~ SEX + INSR_TYPE + USAGE + TYPE_VEHICLE + MAKE +
                 AGE_VEHICLE + SEATS_NUM + CCM_TON_LOG +INSURED_VALUE_log +
                 AMOUNT_CLAIMS_PAID, data = clean_dat_motor)



#Modellzusammenfassung anzeigen
summary(lm_model)

drop1(lm_model, test= "F") #Bei mehrere Kat Var.

coef(lm_model)

#vif(lm_model)


#Residuenanalyse
#Q-Q-Plot 
qqnorm(lm_model$residuals)
qqline(lm_model$residuals, col = "red")

#Residuen vs. Fitted-Werte (Vorhergesagte Werte)
plot(lm_model$fitted.values, lm_model$residuals, 
     main = "Residuals vs Fitted Values", 
     xlab = "Fitted Values", 
     ylab = "Residuals")
abline(h = 0, col = "red")


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model) angezeigt)
r_squared <- summary(lm_model)$r.squared
cat("R-squared:", r_squared, "\n")



```


The model summary shows that the Multiple R-squared value is 0.7308, indicating that the model can explain approximately 73.08% of the variance in premiums. This suggests that the model provides a good fit to the data. The F-test for the overall model is significant (p < 2.2e-16), indicating that the predictors as a group have a substantial effect on the premium.

All predictors have a significant impact on the target variable PREMIUM_log. For instance, the categories SEX and USAGE (usage) have a significant effect on PREMIUM_log. Men pay slightly less compared to women, while certain usages, such as "Fare Paying Passengers," lead to higher premiums. In contrast, usages like "Own Goods" and "Private" are associated with lower premiums.

The coefficient of INSURED_VALUE_log (0.7682) in the model shows that the insured value of the vehicle has a strong influence on the premium level. Since both the insured value and the premium are logarithmically transformed, this means that a 1% increase in the insured value results in approximately a 0.7682% increase in the premium. This illustrates the direct and positive relationship between vehicle value and premium: higher-insured vehicles attract proportionally higher premiums, as they represent a greater financial risk for the insurer. Overall, this coefficient confirms that vehicle value is one of the most significant factors in premium calculation.

The coefficient of AMOUNT_CLAIMS_PAID, with a value of 0.1363, indicates that an increase in the number of claims leads to an increase in the log-transformed premium by approximately 0.1363. This means that each additional claim results in a proportional increase in the premium by about 13.63%. This coefficient highlights that an insured’s claim history has a significant impact on the premium level.

The coefficient of AGE_VEHICLE is 0.0029, indicating that with each additional year of vehicle age, the log-transformed premium increases by about 0.0029. Since the target variable is logarithmic, this implies that an additional year in vehicle age leads to a minimal increase in the premium of approximately 0.29%.

The coefficient of SEATS_NUM is -0.00175, which means that with each additional seat, the log-transformed premium decreases by approximately 0.00175. Given the logarithmic nature of the target variable, this can be interpreted as each additional seat leading to a slight reduction in the premium by around 0.175%.

VIF:
An analysis of multicollinearity revealed that the Variance Inflation Factor (VIF) for the variable INSR_TYPE is 5.85, which suggests possible multicollinearity. This could affect the model’s stability and interpretability and should be considered in further model optimization.

Residuals Analysis

Residuals vs. Fitted Plot:
The Residuals vs. Fitted Plot displays a funnel-shaped pattern, indicating heteroskedasticity. The variance of the residuals increases with higher predicted values, meaning that the model is less accurate for larger premium values. This violates the assumption of constant variance, suggesting that homoskedasticity is not fully met.

Normal Q-Q Plot:
The Normal Q-Q Plot shows that the residuals do not lie perfectly along the line, indicating significant deviations from the theoretical normal distribution, particularly at the tails. These "heavy tails" suggest a non-normal distribution of residuals, potentially due to outliers or unmodeled non-linear relationships.

To improve the model, various measures could be considered. One approach would be to transform the target variable, for example, using a Box-Cox transformation, to reduce heteroskedasticity and achieve a more stable residual variance. Additionally, incorporating non-linear relationships by including polynomial terms or using a generalized linear model (GLM) could be beneficial. This would allow the model to better capture complex relationships between variables, thereby enhancing predictive accuracy.


## Poisson

```{r Poisson_Model, cache=TRUE}

#Data preparation: Aggregate the number of claims per combination 
dat_amount_claims <- clean_dat_motor %>%
  group_by(SEX, INSR_TYPE, USAGE, TYPE_VEHICLE, MAKE, AGE_VEHICLE, SEATS_NUM, CCM_TON, INSURED_VALUE, PREMIUM) %>%
  summarise(Amount_Claims = sum(CLAIM_PAID == "YES"), .groups = 'drop')


hist(dat_amount_claims$Amount_Claims, breaks=2)

mean(dat_amount_claims$Amount_Claims) # calculate mean
var(dat_amount_claims$Amount_Claims)
#The variance is much greater than the mean, which suggests that we will have over-dispersion in the model.

#Poisson Regression:
poisson_model<- glm(Amount_Claims ~ SEX + INSR_TYPE + TYPE_VEHICLE +  MAKE +
                      AGE_VEHICLE + SEATS_NUM + CCM_TON + INSURED_VALUE + PREMIUM,
                      family = poisson(link = "log"), data = dat_amount_claims)

#Summary of the model
summary(poisson_model)
with(poisson_model, cbind(res.deviace = deviance, df= df.residual, p = pchisq(deviance, df= df.residual, lower.tail = F)))



#Coeff
coef(poisson_model)
exp(coef(poisson_model))


#Diagnose overdispersion
deviance(poisson_model) / df.residual(poisson_model)





#neu
#Devianz
#Berechne p-Wert f?r H0: Das Modell beschreibt die Daten ad?quat:
deviance(poisson_model) #D
## [1] 1040
df.residual(poisson_model) #n - (m + 1)
#[1] 47
1 - pchisq(deviance(poisson_model), df.residual(poisson_model))
#Falls D > (n - (m + 1)), dann ist das Modell ungen?gend

#Poisson: Inferenz
#Signifikanztest der einzelnen Parameter
printCoefmat(summary(poisson_model)$coefficients[1:3,], signif.legend= FALSE)


#Wald Vertrauensintervall
#Poisson
coef(poisson_model)["F"]
c(-1, 1) * qnorm(1 - 0.95/2) * summary(poisson_model)$coefficients["F", "Std. Error"]



```
The residuals vs. fitted diagram shows an increasing dispersion of the residuals with increasing estimated values, which indicates heteroscedasticity. This indicates that the variance of the residuals is not constant and supports the assumption of overdispersion, as the variance is significantly greater than the mean. The QQ plot of the residuals shows a strong deviation from the theoretical normal distribution, especially at the ends, which indicates a lack of normal distribution of the residuals. This deviation is typical for Poisson models, but the significant differences indicate overdispersion or possibly missing predictors. The calculation of the ratio of deviance to degrees of freedom (11.86) confirms the overdispersion, as this value is significantly greater than 1 and thus indicates a higher variance in the data than assumed in the Poisson model.

The significance of the predictors in the model becomes clear from the p-values of the coefficient estimates. Almost all predictors show extremely low p-values (p < 0.001), which indicates that they have a significant influence on the number of claims. This high significance strengthens the significance of the correlations found. Nevertheless, the overdispersion remains problematic, as it indicates that the Poisson model may underestimate the variance in the data. Despite the statistical significance of the predictors, a model change, e.g. to a quassi Poisson model or a negative binomial model, could be necessary to improve the model quality and to address the overdispersion appropriately.


### Massnahme 1): Quasi-Poisson-Regression

```{r quasiPois, cache=TRUE}

#Quasi-Poisson
quasi_poisson_model <- glm(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + MAKE + AGE_VEHICLE + SEATS_NUM, 
                           family = quasipoisson, data = dat_amount_claims)

# Summary of the model
summary(quasi_poisson_model)
#F-Test, Vergleiche von geschachtelten Quasi-Likelihood-Modellen (Overdispersion)
drop1(quasi_poisson_model, test= "F")

# Model diagnostics: Residuals vs. Fitted Plot
plot(quasi_poisson_model$fitted.values, residuals(quasi_poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Quasi-Poisson)")
abline(h = 0, col = "red")

# QQ plot of residuals (checking normality)
qqnorm(residuals(quasi_poisson_model, type = "deviance"), main = "QQ Plot of Residuals (Quasi-Poisson)")
qqline(residuals(quasi_poisson_model, type = "deviance"), col = "red")



```
Switching to a quasi-Poisson model to account for overdispersion led to improvements compared to the original Poisson model. The residuals vs. fitted plot shows a reduced dispersion of the residuals at higher estimated values, which indicates a better fit of the variance, although heteroscedasticity still exists. The QQ plot of the residuals shows an improved fit to the theoretical normal distribution, especially in the middle range, while deviations at the edges remain, indicating extreme values or modelling errors. By adjusting the dispersion parameter (29.765) in the quasi-Poisson model, the increased variance compared to the Poisson model is adequately taken into account. The F-test confirms the significance of the variables ‘SEX’, ‘TYPE_VEHICLE’, ‘MAKE’, ‘AGE_VEHICLE’ and ‘SEATS_NUM’. Despite these improvements, there are still slight anomalies in the residuals.

### Massnahme 2): Negative-Binomial-Modell

```{r neg_binom_model, cache=TRUE}

# Negative-Binomial-Regression anpassen
neg_bin_model <- glm.nb(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + MAKE + AGE_VEHICLE + SEATS_NUM,
                        data = dat_amount_claims)

# Zusammenfassung des Modells anzeigen
summary(neg_bin_model)
drop1(neg_bin_model, test= "LRT")

# Exponentierte Koeffizienten anzeigen (um Rate Ratios zu interpretieren)
exp(coef(neg_bin_model))

# Konfidenzintervalle für die Koeffizienten
confint(neg_bin_model)


# Devianz und Freiheitsgrade überprüfen (sollte näher an 1 liegen)
deviance(neg_bin_model) / df.residual(neg_bin_model)

# Residuals vs Fitted Plot
plot(neg_bin_model$fitted.values, residuals(neg_bin_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Negative Binomial)")
abline(h = 0, col = "red")

# QQ-Plot der Residuen
qqnorm(residuals(neg_bin_model, type = "deviance"), main = "QQ Plot of Residuals (Negative Binomial)")
qqline(residuals(neg_bin_model, type = "deviance"), col = "red")

```

The fitting of a negative binomial model shows significant improvements compared to the previous models. The residuals vs fitted plot indicates that the residuals are better distributed overall, especially at larger values of the fitted data, with lower heteroscedasticity. However, the QQ plot of the residuals still shows slight deviations from the normal distribution, especially at the extreme values, which indicates remaining modelling anomalies.

The model shows a significant improvement in terms of overdispersion, as suggested by the ratio of deviance to degrees of freedom (0.822), which is closer to 1 and thus significantly reduces overdispersion. Most predictors continue to show high levels of significance, indicating a strong explanatory power for the number of claims.


## Binomial
```{r Binomial_Model, cache=TRUE}

#Erstellen eines logistischen Regressionsmodells
fit.binom <- glm(CLAIM_PAID ~ SEX + INSR_TYPE + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
             MAKE + SEATS_NUM + CCM_TON + USAGE, 
             data = clean_dat_motor, 
             family = binomial)

# Zusammenfassung des Modells anzeigen
summary(fit.binom)
drop1(fit.binom, test= "LRT")

```

INSR_TYPE and CCM_Ton do not appear to be significant. A new model is adapted without these two variables.

```{r Binomial_Model_sign, cache=TRUE}

#Erstellen eines logistischen Regressionsmodells
fit.binom2 <- glm(CLAIM_PAID ~ SEX +  INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
             MAKE + SEATS_NUM + USAGE, 
             data = clean_dat_motor, 
             family = binomial)

# Zusammenfassung des Modells anzeigen
summary(fit.binom2)
drop1(fit.binom2, test= "LRT")

# Wahrscheinlichkeiten vorhersagen
clean_dat_motor$predicted_probabilities <- predict(fit.binom2, type = "response")

# Klassifikation vorhersagen (0 oder 1)
clean_dat_motor$predicted_class <- ifelse(clean_dat_motor$predicted_probabilities > 0.5, 1, 0)

# Modellgüte prüfen
table(clean_dat_motor$CLAIM_PAID, clean_dat_motor$predicted_class)

# Optional: Genauigkeit berechnen
accuracy <- mean(clean_dat_motor$CLAIM_PAID == clean_dat_motor$predicted_class)
print(paste("Genauigkeit des Modells:", accuracy))

```

Schlechte Modellgüte

### Massnahme 1): Down-Sampling (Balancing) und weniger Variablen

```{r binom_balanced, cache=TRUE}
# Anzahl der YES-Klasse ermitteln
yes_class <- clean_dat_motor[clean_dat_motor$CLAIM_PAID == "YES", ]
no_class <- clean_dat_motor[clean_dat_motor$CLAIM_PAID == "NO", ]

# Anzahl der YES-Beobachtungen
n_yes <- nrow(yes_class)

# Zufällige Auswahl aus der NO-Klasse, sodass sie die gleiche Grösse wie die YES-Klasse hat
set.seed(42)  # Für Reproduzierbarkeit
no_class_undersampled <- no_class[sample(1:nrow(no_class), n_yes), ]

# Erstellen eines neuen Datensatzes, der YES und die undersampelte NO-Klasse kombiniert
clean_dat_motor_undersampled <- rbind(yes_class, no_class_undersampled)

# Überprüfen der neuen Klassenverteilung
table(clean_dat_motor_undersampled$CLAIM_PAID)

# Logistisches Regressionsmodell mit undersampelten Daten
fit.binom_undersampled <- glm(CLAIM_PAID ~ SEX + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
                             MAKE + SEATS_NUM + USAGE, 
                             data = clean_dat_motor_undersampled, 
                             family = binomial)

# Zusammenfassung des neuen Modells
summary(fit.binom_undersampled)
drop1(fit.binom_undersampled, test= "LRT") #SEATS_NUM not sign





# Logistisches Regressionsmodell mit undersampelten Daten
fit.binom_undersampled2 <- glm(CLAIM_PAID ~ SEX + INSURED_VALUE + PREMIUM + AGE_VEHICLE + 
                             MAKE + USAGE, data = clean_dat_motor_undersampled, 
                             family = binomial)

# Zusammenfassung des neuen Modells
summary(fit.binom_undersampled2)
drop1(fit.binom_undersampled2, test= "LRT")

# Wahrscheinlichkeiten vorhersagen
clean_dat_motor_undersampled$predicted_probabilities <- predict(fit.binom_undersampled2, type = "response")

# Klassifikation vorhersagen (0 oder 1)
clean_dat_motor_undersampled$predicted_class <- ifelse(clean_dat_motor_undersampled$predicted_probabilities > 0.5, 1, 0)

# Modellgüte prüfen
table(clean_dat_motor_undersampled$CLAIM_PAID, clean_dat_motor_undersampled$predicted_class)

# Genauigkeit berechnen
accuracy_undersampled <- mean(clean_dat_motor_undersampled$CLAIM_PAID == clean_dat_motor_undersampled$predicted_class)
print(paste("Genauigkeit des undersampelten Modells:", accuracy_undersampled))




# Umwandlung in Faktoren für die Auswertung
predicted_class <- as.factor(clean_dat_motor_undersampled$predicted_class)
actual_class <- as.factor(clean_dat_motor_undersampled$CLAIM_PAID)


# Sicherstellen, dass predicted_class und actual_class die gleichen Levels haben
levels(predicted_class) <- levels(actual_class)

# Levels überprüfen
levels(predicted_class)
levels(actual_class)

# Berechnung der Metriken
confusionMatrix(predicted_class, actual_class)


```

weitere Massnahmen: Schwellenwertanpassubg (hat wenig gebracht) Interaktionen
## Generalised Additive Model (GAM)
```{r GAM, cache=TRUE}
# TODO

```

## Neural Network
```{r Neural_Network, cache=TRUE}
# TODO

```


## Support Vector Machine (SVM)
```{r SVM preparation}
set.seed(123)
svm_data <- clean_dat_motor[sample(nrow(clean_dat_motor), 100000, replace = FALSE), ]

hist(svm_data$PREMIUM_LOG, main = "Premium Distribution", xlab = "Premium", breaks = 30)

plot(density(svm_data$PREMIUM_LOG, na.rm = TRUE), main = "Density of Premium")

percentiles <- quantile(svm_data$PREMIUM_LOG, probs = c(0.25,0.5,0.75))

# Create custom categories for PREMIUM based on percentiles
svm_data$premium_category <- cut(svm_data$PREMIUM_LOG, 
                                 breaks = c(-Inf, percentiles[1], percentiles[2], percentiles[3], Inf), 
                                 labels = c("low", "medium", "high", "very_high"))
print(table(svm_data$premium_category
            ))

# Splitting into training and testing test
trainIndex <- createDataPartition(svm_data$premium_category, p = 0.7, list = FALSE)
train <- svm_data[trainIndex, ]
test <- svm_data[-trainIndex, ]

#plotting to see if it can be linearly split

selected_data <- svm_data[, c("AGE_VEHICLE", "INSURED_VALUE_LOG", "CLAIM_PAID_USD_LOG", "premium_category")]
library(GGally)
ggpairs(selected_data, aes(color = premium_category))
```

Given the overlaps and distribution of data points across different categories, the data does not appear to be linearly separable. This means that a non-linear kernel would likely be a better choice for capturing the complex relationships and boundaries between the classes.

```{r SVM radial, cache=TRUE}

fit <- svm(premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, 
             data = train, 
             kernel = "radial")

summary(fit)

predictions <- predict(fit, test)
confusionMatrix(predictions, test$premium_category)

```
Performance Analysis
Overall Accuracy:

Accuracy: 71.62% is still a solid performance for a four-class classification task but is slightly lower than before (72.24%). This drop could be due to sample variation, indicating the model may be sensitive to the specific data distribution in the training set.
Class-Specific Performance:

Class Sensitivity:
The model performs best in identifying the “very high” class (Sensitivity = 0.8545), meaning it effectively detects most "very high" premium cases.
The “low” (67.35%) and “high” (67.89%) classes show lower sensitivities, which implies that the model struggles to identify these categories as accurately. Misclassifications here likely contribute to the reduced accuracy.
Specificity: High specificity across all classes, particularly for “low” (96.30%) and “very high” (91.17%), suggests the model effectively recognizes cases that do not belong to these categories.
Positive Predictive Value (Precision):
Precision is reasonable across classes but lowest for “high” (60.51%) and “medium” (67.54%), indicating that the model may confuse these categories with others.
Balanced Accuracy:

Balanced accuracy is lower for "medium" (77.63%) and "high" (76.57%) compared to "low" and "very high." This imbalance suggests the model is slightly less effective in distinguishing between “medium” and “high” categories.
Recommendations for Improvement
Given the above observations, here are several suggestions to improve model performance:

Hyperparameter Tuning:

Increase Cost: Since the model has moderate sensitivity for “low” and “high” classes, increasing the cost parameter could encourage a tighter fit to these categories, potentially reducing the number of misclassifications. However, be cautious not to set it too high, as this could overfit on the “very high” class.
Gamma Tuning: Experiment with slightly higher values of gamma to see if it improves precision in "medium" and "high" classes. This could make the model more responsive to feature distinctions within these overlapping categories.

Alternative Kernel Exploration:

Polynomial Kernel: For cases where there is complex overlap between classes (e.g., "medium" and "high"), the polynomial kernel can sometimes capture these relationships better than the radial kernel.
Sigmoid Kernel: If the data has a certain linear-separability structure, experimenting with the sigmoid kernel could also improve classification.
Feature Engineering:

Interaction Terms: Create interaction terms between significant predictors, such as AGE_VEHICLE * INSURED_VALUE_LOG or CLAIM_PAID_USD_LOG * CCM_TON_LOG. These could help the model better distinguish between similar categories by capturing nuanced relationships.
Dimensionality Reduction: Try PCA (Principal Component Analysis) to reduce noise in the data. By retaining only the principal components that explain the most variance, you can simplify the feature space, potentially improving the model’s accuracy and generalization.
Class Rebalancing Techniques:

If there’s a slight imbalance in the data (e.g., fewer instances in "high" or "medium" categories), techniques like SMOTE (Synthetic Minority Over-sampling Technique) could help balance the classes, improving model performance on the lower-represented classes.
Try Ensemble Models for Comparison:

You may also consider training a Random Forest or Gradient Boosting model as a baseline to compare against SVM. These models can sometimes capture complex relationships and reduce misclassification for categories like "medium" and "high."


```{r SVM improvement from model#1}

# Perform hyperparameter tuning with tune()

# Define the formula with selected features

# Tune the model
tune.out <- tune(svm, premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, data = train, kernel = "radial",
                 ranges = list(cost = c(0.1, 1, 10),
                               gamma = c(0.5, 1, 2)))

# View the best parameters and summary
print(tune.out)
best_model <- tune.out$best.model

# Print the best cost and gamma values
best_params <- tune.out$best.parameters
cat("Best Cost:", best_params$cost, "\n")
cat("Best Gamma:", best_params$gamma, "\n")

# Fit the best model on the train data
fit.improved <- best_model


# library(caret)
# tune_grid <- expand.grid(C = c(1, 10, 100), gamma = c(0.01, 0.1, 1))
# tuned_model <- train(premium_category ~ SEX + AGE_VEHICLE + INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + CCM_TON_LOG + MAKE + USAGE, 
#                      data = train, 
#                      method = "svmRadial", 
#                      tuneGrid = tune_grid, 
#                      trControl = trainControl(method = "cv"))

```
# Conclusion




# Reserve
### Massnahme 1):  Interaktionen

```{r lm_interaktion, cache=TRUE}

#Coole Plots zum Aufzeigen von Interaktionen:

# Boxplot von PREMIUM_log nach MAKE und USAGE
ggplot(clean_dat_motor, aes(x=MAKE, y=PREMIUM_log, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen MAKE und USAGE", x = "MAKE", y = "PREMIUM_log")

# Boxplot von PREMIUM_log nach TYPE_VEHICLE und USAGE
ggplot(clean_dat_motor, aes(x=TYPE_VEHICLE, y=PREMIUM_log, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen TYPE_VEHICLE und USAGE", x = "TYPE_VEHICLE", y = "PREMIUM_log")

# Scatterplot von INSURED_VALUE_log und PREMIUM_log nach USAGE
ggplot(clean_dat_motor, aes(x=INSURED_VALUE_log, y=PREMIUM_log, color=USAGE)) + 
  geom_point(alpha=0.5) + 
  geom_smooth(method="lm", se=FALSE) +
  labs(title = "Interaktion zwischen INSURED_VALUE_log und USAGE", x = "INSURED_VALUE_log", y = "PREMIUM_log")

```

