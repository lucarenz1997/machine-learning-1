---
title: "ML1"
authors: "Alvaro Cervan, Luca Renz, Rafaella Miranda-Sousa"
date: "2024-01-10"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_packages, echo =FALSE, cache=TRUE}

#Install and import libraries.
if (!require("car")) install.packages("car")  # Support Vector Machine (SVM)
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("ROI")) install.packages("ROI")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("corrplot")) install.packages("corrplot")
if (!require("dplyr")) install.packages("dplyr")
if (!require("GGally")) install.packages("GGally")
if (!require("mgcv")) install.packages("mgcv")  # Generalised Additive Model (GAM)
if (!require("nnet")) install.packages("nnet")  # Neural Networks
if (!require("e1071")) install.packages("e1071")  # Support Vector Machine (SVM)
if (!require("MASS")) install.packages("MASS")

library(car)
library(readr,quietly = T)
library(ggplot2, quietly = T)
library(ROI, quietly = T)
library(tidyverse, quietly = T)
library(lubridate, quietly = T)
library(corrplot, quietly = T)
library(dplyr)
library(GGally)
library(mgcv)  # For Generalised Additive Models
library(nnet)  # For Neural Networks
library(e1071)  # For Support Vector Machine

```
Notizen Rafi
SVM Teil:
Cross validation or other methods for model comparing must be used on one single
methods (e.g. you use Cross Validation to compare 2-3 SVM models).
• Students are free to choose a measure of fit that they find more appropriate.
• In case students cannot find an appropriate measure of fit, they can use the Root Mean
Squared Error (RMSE).

Schließlich ist zu beachten, dass die Zusammenstellung von Dokumenten einige Zeit in Anspruch nehmen kann... insbesondere wenn komplexe
Modelle angepasst werden
- In diesen Fällen können Sie die Argumentationsoption cache = TRUE verwenden, so dass ein Chunk nur dann neu ausgewertet wird
nur dann neu ausgewertet wird, wenn er seit der letzten Kompilierung geändert wurde. Wenn der Chunk unverändert blieb
unverändert, dann werden die alten Ergebnisse verwendet



# Data Preprocessing

Aus Quelle:
Some predictors such as carrying capacity and seat number are removed from the dataset prior
to data analysis and modeling since they are not correctly coded.


CHATGPT
CCM TON
Es macht keinen Sinn, dass Fahrzeuge einen Wert von 0 für die Variable CCM_TON haben, wenn diese Variable den Hubraum oder das Gewicht des Motors in Kubikzentimetern (ccm) oder Tonnen angibt.
Warum?
Der Hubraum (ccm) gibt das Volumen der Zylinder eines Verbrennungsmotors an. Ein Wert von 0 wäre unplausibel, da ein Fahrzeug ohne Hubraum keinen funktionsfähigen Motor hätte.
Wenn CCM_TON das Gewicht des Motors in Tonnen angibt, wäre ebenfalls ein Wert von 0 unplausibel, da ein Fahrzeug ohne Motorgewicht nicht funktionsfähig wäre.

```{r data_prep, echo=FALSE, cache=TRUE}

# DATA LOAD
raw_dat_motor <- read_csv("data/motor_data14-2018.csv", show_col_types = FALSE)

dim(raw_dat_motor)
str(raw_dat_motor)

#DATA PREP

#EFFECTIVE_YR
#Entfernen der Spalte EFFECTIVE_YR (Hat keinen Nutzen, da nicht entziffert werden kann)
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "EFFECTIVE_YR")]

#CARRYING_CAPACITY
#Entfernen der Spalte CARRYING_CAPACITY
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "CARRYING_CAPACITY")]

#CLAIM_PAID
raw_dat_motor$CLAIM_PAID_USD <- ifelse(is.na(raw_dat_motor$CLAIM_PAID), 0, raw_dat_motor$CLAIM_PAID)
raw_dat_motor$CLAIM_PAID <- ifelse(raw_dat_motor$CLAIM_PAID_USD == 0, "NO", "YES")

# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

#SEX
raw_dat_motor$SEX <- factor(raw_dat_motor$SEX, 
                   levels = c(0, 1, 2), 
                   labels = c("Legal entity", "Male", "Female"))
table(raw_dat_motor$SEX)

#INSR_BEGIN
raw_dat_motor$INSR_BEGIN <- dmy(raw_dat_motor$INSR_BEGIN)

#INSR_END
raw_dat_motor$INSR_END <- dmy(raw_dat_motor$INSR_END)

#INSR_TYPE
raw_dat_motor$INSR_TYPE <- factor(raw_dat_motor$INSR_TYPE, 
                         levels = c(1201, 1202, 1204), 
                         labels = c("Private", "Commercial", "Motor trade road risk"))

#INSURED_VALUE
#Überprüfen der Anzahl der fehlenden Werte
missing_values <- sum(is.na(raw_dat_motor$INSURED_VALUE))
cat("Fehlende Werte in INSURED_VALUE:", missing_values, "\n")

#Zusammenfassung der statistischen Kennzahlen
summary_stats <- summary(raw_dat_motor$INSURED_VALUE)
cat("Zusammenfassung der statistischen Kennzahlen von INSURED_VALUE:\n")
print(summary_stats)

#Ermittlung der Anzahl der Einträge, die 0 als Wert haben
zero_values <- sum(raw_dat_motor$INSURED_VALUE == 0, na.rm = TRUE)
cat("Anzahl der Einträge mit dem Wert 0 in INSURED_VALUE:", zero_values, "\n")

#Überprüfe, wie viele Datensätze betroffen sind
zero_insured_value <- raw_dat_motor[raw_dat_motor$INSURED_VALUE == 0, ]
cat("Anzahl der Datensätze mit INSURED_VALUE = 0:", nrow(zero_insured_value), "\n")

#Zusammenfassung der betroffenen Datensätze nach verschiedenen Variablen, um Muster zu erkennen
cat("Verteilung der Versicherungstypen (INSR_TYPE) bei INSURED_VALUE = 0:\n")
table(raw_dat_motor$INSR_TYPE) #Alle
print(table(zero_insured_value$INSR_TYPE)) #nur 0

cat("\nVerteilung der Fahrzeugtypen (TYPE_VEHICLE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$TYPE_VEHICLE))

cat("\nVerteilung der Fahrzeugnutzung (USAGE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$USAGE))

#Statistische Kennzahlen für andere Variablen bei INSURED_VALUE = 0 (z.B. PREMIUM)
cat("\nZusammenfassung der Prämien (PREMIUM) bei INSURED_VALUE = 0:\n")
summary(zero_insured_value$PREMIUM)

#Visualisierung der Fahrzeugnutzung bei INSURED_VALUE = 0
ggplot(zero_insured_value, aes(x = USAGE)) +
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Verteilung der Fahrzeugnutzung bei INSURED_VALUE = 0", x = "Fahrzeugnutzung", y = "Anzahl") +
  theme_minimal()

#Fazit: Es wurde kein Zusammenhang festgestellt. Vermutlich ist der Versicherungswert von 0 darauf zurückzuführen, dass gesetzlich nur eine Haftpflichtversicherung erforderlich ist. In diesen Fällen gibt es keinen festgelegten Wert für Schäden am Fahrzeug selbst. Daher werden Datensätze mit einem INSURED_VALUE von 0 aus der Analyse entfernt, da sie keine relevanten Informationen für die Bewertung von Fahrzeugwerten enthalten.

#Entfernen der Zeilen, bei denen INSURED_VALUE gleich 0 ist
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE != 0, ]

#Überprüfen, ob die Zeilen erfolgreich entfernt wurden
cat("Anzahl der verbleibenden Datensätze:", nrow(raw_dat_motor), "\n")

#Verteilung von INSURED_VALUE visualisieren (Histogramm)
ggplot(raw_dat_motor, aes(x = INSURED_VALUE)) +
  geom_histogram(binwidth = 50000, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Verteilung von INSURED_VALUE", x = "Versicherter Wert", y = "Häufigkeit") +
  theme_minimal()

#Boxplot zur Identifizierung von Ausreissern
ggplot(raw_dat_motor, aes(y = INSURED_VALUE)) +
  geom_boxplot(fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "Boxplot von INSURED_VALUE", y = "Versicherter Wert") +
  theme_minimal()

#Überprüfung der statistischen Kennzahlen ohne die 0-Werte
cat("Zusammenfassung der statistischen Kennzahlen ohne 0-Werte:\n")
print(summary(raw_dat_motor$INSURED_VALUE))

#Verteilung der log-transformierten INSURED_VALUE (nur für nicht-null Werte)
ggplot(raw_dat_motor[raw_dat_motor$INSURED_VALUE > 0, ], aes(x = log(INSURED_VALUE))) +
  geom_histogram(binwidth = 0.2, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Log-transformierte Verteilung von INSURED_VALUE (ohne Nullwerte)", x = "log(Versicherter Wert)", y = "Häufigkeit") +
  theme_minimal()

summary(raw_dat_motor$INSURED_VALUE)

#Ausreisser INSURED_VALUE entfernen 
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE >= 10, ]
summary(raw_dat_motor$INSURED_VALUE)

#Workspace
rm(zero_insured_value)

#PREMIUM
#Uberpruefung ob entfernen von PREMIUM = 0 vom Datensatz valide ist
data.frame(
  PREMIUM_0_Percent = round(100 * sum(raw_dat_motor$PREMIUM == 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_NA_Percent = round(100 * sum(is.na(raw_dat_motor$PREMIUM)) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_MORE_Percent = round(100 * sum(raw_dat_motor$PREMIUM > 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4)
)

#Entfernen der Zeilen, bei denen PREMIUM NA oder 0 ist
raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$PREMIUM) | raw_dat_motor$PREMIUM == 0), ]


# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

# OBJECT_ID
# Anzahl der Gesamtzeilen im Datensatz
total_rows <- nrow(raw_dat_motor)

# Anzahl der einzigartigen OBJECT_IDs
unique_object_ids <- length(unique(raw_dat_motor$OBJECT_ID))

# Überprüfen, ob OBJECT_IDs einmalig sind
if (total_rows == unique_object_ids) {
  cat("Die OBJECT_IDs sind einmalig.\n")
} else {
  cat("Die OBJECT_IDs sind NICHT einmalig.\n")
  cat("Anzahl der Duplikate:", total_rows - unique_object_ids, "\n")
  
  # Häufigkeit der OBJECT_IDs
  object_id_counts <- table(raw_dat_motor$OBJECT_ID)
  
  # Durchschnittliche und maximale Häufigkeit von OBJECT_ID
  avg_object_id_freq <- mean(object_id_counts)
  max_object_id_freq <- max(object_id_counts)
  
  cat("Durchschnittliche Häufigkeit der OBJECT_ID:", round(avg_object_id_freq, 3), "\n")
  cat("Maximale Häufigkeit der OBJECT_ID:", max_object_id_freq, "\n")
  
  # Häufigkeit der Kombination von OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE und PREMIUM
  combo_counts <- raw_dat_motor %>%
    group_by(OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM) %>%
    summarise(count = n(), .groups = 'drop')
  
  # Durchschnittliche und maximale Häufigkeit der Kombination
  avg_combo_freq <- mean(combo_counts$count) # Durchschnittliche Häufigkeit der Kombination
  max_combo_freq <- max(combo_counts$count)   # Maximale Häufigkeit der Kombination
  
  cat("Durchschnittliche Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", round(avg_combo_freq, 3), "\n")
  cat("Maximale Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", max_combo_freq, "\n")
}

#Teilweise gibt es bei CLAIM_PAID== YES eine vervielfachung
#Korrektur bzw. entfernen dieser mehrfachen Zeilen
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSR_TYPE, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  # Zähle die Anzahl der Zeilen in jeder Gruppe
  mutate(group_size = n()) %>%
  ungroup() %>%
  # Entferne Zeilen nur, wenn es eine Doppelzeile gibt und CLAIM_PAID == "NO" und CLAIM_PAID_USD <= 1
  filter(!(group_size > 1 & CLAIM_PAID == "NO" & CLAIM_PAID_USD <= 1)) %>%
  dplyr::select(-group_size)  # Entferne die Hilfsspalte

#Korrektur Wiederspruch bei INSR_TYPE
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  filter(!(n() > 1 & INSR_TYPE != "Commercial")) %>%  # Behalte nur die Zeilen mit "Commercial"
  ungroup()  # Ungroup, um das Gruppierungsobjekt zu entfernen

# Clear Workspace
rm(list = setdiff(ls(), "raw_dat_motor"))


#PROD_YEAR
#Zeilen mit PROD_YEAR NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$PROD_YEAR),]
summary(raw_dat_motor$PROD_YEAR)

#SEATS_NUM
#Analyse SEATS_NUM: Anzahl der Zeilen mit SEATS_NUM == 0, NA und anderen Werten
data.frame(
  SEATS_NUM_0 = sum(raw_dat_motor$SEATS_NUM == 0, na.rm = TRUE),
  SEATS_NUM_NA = sum(is.na(raw_dat_motor$SEATS_NUM)),
  SEATS_NUM_OTHER = sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE)
)
#Relativ: Prozentsatz der Zeilen mit SEATS_NUM == 0, NA oder anderen Werten
data.frame(
  SEATS_NUM_0_or_NA_Percent = 100 * sum(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0) / nrow(raw_dat_motor),
  SEATS_NUM_OTHER_Percent = 100 * sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE) / nrow(raw_dat_motor)
)
#Zeilen mit SEATS_NUM NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$SEATS_NUM),]
summary(raw_dat_motor$SEATS_NUM)

#Problematik: Es gibt SEATS_NUM mit 0

##Erstellen separater Datensätze für SEATS_NUM == 0 und SEATS_NUM > 0
#data_seats_num_0 <- subset(raw_dat_motor, SEATS_NUM == 0)
#data_seats_num_other <- subset(raw_dat_motor, SEATS_NUM > 0 & !is.na(SEATS_NUM))
## Tabellen der Fahrzeugtypen für beide Datensätze
#table(data_seats_num_0$TYPE_VEHICLE)
#table(data_seats_num_other$TYPE_VEHICLE)

##SEATS_NUM Alternative 1: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
##Liste der Fahrzeugtypen, bei denen SEATS_NUM == 0 unplausibel ist (Trailers and semitrailers, Tractor, Tanker werden gelassen)
#unplausible_types <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Station Wagones", "Tanker", "Truck")
##Entfernen der Zeilen, bei denen SEATS_NUM == 0 und der Fahrzeugtyp unplausibel ist
#raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$SEATS_NUM == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types), ]
#
#
##SEATS_NUM Alternative 2: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
#raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0), ]
#
##SEATS_NUM Alternative 3: Entfernen der SEATS_NUM-Spalte, da viele NA und schlechte Datenqualität
##raw_dat_motor <- subset(raw_dat_motor, select = -SEATS_NUM)

#TYPE_VEHICLE
#Entfernen der Zeilen, bei denen TYPE_VEHICLE == "Trade plates" Da zu wenige Auspraegungen (5)
#table(raw_dat_motor$TYPE_VEHICLE)
raw_dat_motor <- raw_dat_motor[raw_dat_motor$TYPE_VEHICLE != "Trade plates", ]

#CCM_TON
summary(raw_dat_motor$CCM_TON)
#Relativ CCM_TON 0
data.frame(
  CCM_TON_0_Percent = 100 * mean(raw_dat_motor$CCM_TON == 0, na.rm = TRUE),
  CCM_TON_MORE_Percent = 100 * mean(raw_dat_motor$CCM_TON > 0, na.rm = TRUE))
# Erstellen separater Datensätze für CCM_TON == 0 und CCM_TON > 0
data_CCM_TON_0 <- subset(raw_dat_motor, CCM_TON == 0)
data_CCM_TON_other <- subset(raw_dat_motor, CCM_TON > 0 & !is.na(CCM_TON))
# Tabellen der Fahrzeugtypen für beide Datensätze
table(data_CCM_TON_0$TYPE_VEHICLE)
table(data_CCM_TON_other$TYPE_VEHICLE)
# Liste der Fahrzeugtypen, bei denen CCM_TON == 0 unplausibel ist (Tractor,Trailers and semitrailers werden gelassen)
unplausible_types_ccm <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Truck", "Station Wagones", "Tanker", "Special construction")
# Entfernen der Zeilen, bei denen CCM_TON == 0 und der Fahrzeugtyp unplausibel ist
raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$CCM_TON == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types_ccm), ]


#USAGE
#table(raw_dat_motor$USAGE)
#Wenige Ausprägungen entfernen
raw_dat_motor <- subset(raw_dat_motor, !(USAGE %in% c("Fire fighting", "Learnes", "Others")))



#MAKE
#Zeilen mit MAKE NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$MAKE),]
#MAKE in Grossbuchstaben umwandeln
raw_dat_motor$MAKE <- toupper(raw_dat_motor$MAKE)

#Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
#Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")
# Behalten von Zeilen, in denen MAKE mit Buchstaben beginnt
raw_dat_motor <- raw_dat_motor[grepl("^[A-Za-z]", raw_dat_motor$MAKE), ]
table(raw_dat_motor$MAKE)


#Manuelle Korrekturen von MAKE
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PORCHE", "FORSCHE")] <- "PORSCHE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE == "YAMHA"] <- "YAMAHA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("VOLKSWAGON", "VOLKS WAGON")] <- "VOLKSWAGEN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("TOYOTAA", "TOYOTA*", "TOYTA", "TOYOTA AUTOMOBILE",
                                       "TOYATA", "T0Y0TA", "COMPACT YARIS", "YARIS",
                                       "LAND CRUISER", "VITZ")] <- "TOYOTA"
raw_dat_motor$MAKE[grepl("^TOYOTA", raw_dat_motor$MAKE)] <- "TOYOTA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("NISAN", "NISSAN*")] <- "NISSAN"
raw_dat_motor$MAKE[grepl("^NISSAN", raw_dat_motor$MAKE)] <- "NISSAN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENGE  ROVER", "RANGEROVER")] <- "RANGE ROVER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENALT", "RENUALT", "RENAULT/STOLARCZYK", "RENAULT*")] <- "RENAULT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PEUGEOUT", "PEJOT", "PAGOT")] <- "PEUGEOT"
raw_dat_motor$MAKE[grepl("^PEUGEOT", raw_dat_motor$MAKE)] <- "PEUGEOT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("BMB")] <- "BMW"
raw_dat_motor$MAKE[grepl("^BMW", raw_dat_motor$MAKE)] <- "BMW"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MISTIBUSH", "MITSUBISHI*", "MITSUBUSHI")] <- "MITSUBISHI"
raw_dat_motor$MAKE[grepl("^FORD", raw_dat_motor$MAKE)] <- "FORD"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SPORTAGE")] <- "KIA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MERCEEDES", "MERCEEDICE", "MERCEDICE", "MERCHEDES")] <- "MERCEDES"
raw_dat_motor$MAKE[grepl("^MERCEDES", raw_dat_motor$MAKE)] <- "MERCEDES"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SUZIKE")] <- "SUZUKI"
raw_dat_motor$MAKE[grepl("^SUZUKI", raw_dat_motor$MAKE)] <- "SUZUKI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HYUNDI GETZ")] <- "HYUNDAI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("ISUSU")] <- "ISUZU"
raw_dat_motor$MAKE[grepl("^ISUZU", raw_dat_motor$MAKE)] <- "ISUZU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("FRANKUN IVECO")] <- "IVECO"
raw_dat_motor$MAKE[grepl("^IVECO", raw_dat_motor$MAKE)] <- "IVECO"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LANDROVER")] <- "LAND ROVER"


raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DONGFANG", "DONFING", "DONG FENGSHEN", "DONG FENG")] <- "DONGFENG"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MAHANDRA")] <- "MAHINDRA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HOLAND CAR")] <- "ABAY"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("CALABRASE")] <- "CALABRESE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("GELYION", "GENLION", "GELION", "GENLYONIVECO", "HONGYAN")] <- "GENLYON"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DHATSU", "DIATSU", "DIAHATSU")] <- "DAIHATSU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DAWOO", "DAWWO", "DEAWOO", "DEAWOO USE")] <- "DAEWOO"
raw_dat_motor$MAKE[grepl("^LIFAN", raw_dat_motor$MAKE)] <- "LIFAN"
raw_dat_motor$MAKE[grepl("^BAIC", raw_dat_motor$MAKE)] <- "BAIC"
raw_dat_motor$MAKE[grepl("^LOADER", raw_dat_motor$MAKE)] <- "LOADER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MOTOR CYCLE", "MOTOR  CYCLE")] <- "MOTORCYCLE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("AUTO", "AUTOMOBIL")] <- "AUTOMOBILE"
raw_dat_motor$MAKE[grepl("^CATERPILLAR", raw_dat_motor$MAKE)] <- "CATERPILLAR"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LIBER DOZER", "LIBERR MOBILE CRANE",
                                       "LIEBERR MOBILE CRANE", "LEABER CATO CRANE",
                                       "LEBHER CRANE", "CRANE LEBEHER",
                                       "CRANE LEBHERER", "LIBER", "LIBEHER CRANE",
                                       "LIBERR MOBILECRANE", "CRANELEBHER")] <- "LIEBHERR"

#table(raw_dat_motor$MAKE)

#Zähle die Anzahl der Einträge pro MAKE, wo CLAIM_PAID == "YES"
count_claims_paid <- raw_dat_motor %>%
  group_by(MAKE, CLAIM_PAID ) %>%                 # Gruppiere nach MAKE
  summarise(count = n()) %>%        # Zähle die Einträge pro Gruppe
  arrange(desc(count)) 

###############################################################################################


#Liste der gewünschten Fahrzeughersteller (Make)
selected_makes <- c("TOYOTA", "ISUZU", "NISSAN", "IVECO", "SINO HOWO", 
                    "MITSUBISHI", "BISHOFTU", "LIFAN", "FORD", "HYUNDAI", 
                    "MAZDA", "GEELY", "DAEWOO", "MERCEDES", "TATA", 
                    "FIAT", "SINO", "SUZUKI", "GENLYON", "RENAULT", "VOLVO")

#Filtern des Datensatzes nach den ausgewählten Fahrzeugherstellern
clean_dat_motor <- subset(raw_dat_motor, MAKE %in% selected_makes)

#Wenige Ausprägungen entfernen
#table(clean_dat_motor$SEX) #OK

#table(clean_dat_motor$USAGE)
clean_dat_motor <- subset(clean_dat_motor, !(USAGE %in% c("Agricultural Any Farm",
                                                "Agricultural Own Farm",
                                                "Special Construction", "Taxi")))

#table(clean_dat_motor$TYPE_VEHICLE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(TYPE_VEHICLE %in% c("Tractor")))

#table(clean_dat_motor$INSR_TYPE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(INSR_TYPE %in% c("Motor trade road risk")))

#table(clean_dat_motor$MAKE)

#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))


###############################################################################################

#Vergleich zum Rohdatensatz
#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

###############################################################################################

#NA
colSums(is.na(raw_dat_motor)) 
colSums(is.na(clean_dat_motor)) 

#Umwandlung der kategorialen Variablen in Factor-Variablen
clean_dat_motor$OBJECT_ID <- as.factor(clean_dat_motor$OBJECT_ID)
clean_dat_motor$SEX <- as.factor(clean_dat_motor$SEX)
clean_dat_motor$INSR_TYPE <- as.character(clean_dat_motor$INSR_TYPE)
clean_dat_motor$INSR_TYPE <- as.factor(clean_dat_motor$INSR_TYPE)
clean_dat_motor$MAKE <- as.factor(clean_dat_motor$MAKE)
clean_dat_motor$USAGE <- as.factor(clean_dat_motor$USAGE)
clean_dat_motor$CLAIM_PAID <- as.factor(clean_dat_motor$CLAIM_PAID)
clean_dat_motor$TYPE_VEHICLE <- as.factor(clean_dat_motor$TYPE_VEHICLE)


# Clear Workspace
rm(list = setdiff(ls(), c("raw_dat_motor", "clean_dat_motor")))
rm(raw_dat_motor)
clean_dat_motor2<- clean_dat_motor

```





# Models
## Linear Model

```{r linear_model, cache = TRUE}

#Modell erstellen
lm_model <- lm(PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + INSURED_VALUE + CLAIM_PAID_USD + PROD_YEAR + SEATS_NUM + CCM_TON, data = clean_dat_motor)

#Modellzusammenfassung anzeigen
summary(lm_model)
Anova(lm_model, type="II")  # Type II oder III je nach Modellstrukt

#Residuen-Plots für Modell-Diagnose
#Plot der Residuen vs. Fit-Werte
plot(lm_model$fitted.values, lm_model$residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

#QQ-Plot der Residuen (Überprüfung der Normalverteilung)
qqnorm(lm_model$residuals, main = "QQ Plot of Residuals")
qqline(lm_model$residuals, col = "red")


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model) angezeigt)
r_squared <- summary(lm_model)$r.squared
cat("R-squared:", r_squared, "\n")

```

### Massnahme: Transformation

```{r analyse_variablen, cache=TRUE}

#Analyse Variablen
numeric_vars <- c("PREMIUM", "INSURED_VALUE", "CLAIM_PAID_USD", "PROD_YEAR", "SEATS_NUM", "CCM_TON")

#Histogramme erstellen
par(mfrow = c(2, 3))  # 2 Zeilen, 3 Spalten für die Plots
for (var in numeric_vars) {
  hist(clean_dat_motor[[var]], main = paste("Histogram of", var), xlab = var, col = "lightblue", breaks = 30)
}
par(mfrow = c(1, 1))  # Zurück zu einem einzelnen Plot pro Seite

#Massnahme: Transformation der Variablen
# Log-Transformation für stark rechtsschiefe Variablen
clean_dat_motor$PREMIUM_LOG <- log(clean_dat_motor$PREMIUM + 1)  # Hinzufügen von +1 um log(0) zu vermeiden
clean_dat_motor$INSURED_VALUE_LOG <- log(clean_dat_motor$INSURED_VALUE + 1)
clean_dat_motor$CLAIM_PAID_USD_LOG <- log(clean_dat_motor$CLAIM_PAID_USD + 1)
clean_dat_motor$CCM_TON_LOG <- log(clean_dat_motor$CCM_TON + 1)


```

Schiefe Verteilungen vorhanden

```{r lm logtrans}

# Modell erstellen mit den log-transformierten Variablen
lm_model_log <- lm(PREMIUM_LOG ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                   INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + PROD_YEAR + SEATS_NUM + CCM_TON_LOG, 
                   data = clean_dat_motor)

# Zusammenfassung des neuen Modells
summary(lm_model_log)
Anova(lm_model_log, type="II")  # Type II oder III je nach Modellstrukt

#Residuen-Plots für Modell-Diagnose
#Plot der Residuen vs. Fit-Werte
plot(lm_model_log$fitted.values, lm_model_log$residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

#QQ-Plot der Residuen (Überprüfung der Normalverteilung)
qqnorm(lm_model_log$residuals, main = "QQ Plot of Residuals")
qqline(lm_model_log$residuals, col = "red")

#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model_log$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model_log) angezeigt)
r_squared <- summary(lm_model_log)$r.squared
cat("R-squared:", r_squared, "\n")

```

Problem:
Residuen
Varianz der Residuen ist nicht konstant. Residuen sind nicht gleichmässig um die Nulllinie verteilt
Modell erklärt möglicherweise die Abhängigkeit der Residuen von den Fit-Werten nicht vollständig 

QQPlot:
Problem: Residuen sind nicht vollständig normalverteilt

### Massnahme: Ausreisser entfernen

```{r lm_Ausreisser, cache=TRUE}


#Berechnung der Cook's Distance
cooksD <- cooks.distance(lm_model_log)
#Identifikation von Beobachtungen mit hoher Cook's Distance
influential_points <- which(cooksD > (4 / nrow(clean_dat_motor)))
clean_dat_motor[influential_points, ]

#Modell ohne Ausreisser
#Modell erstellen mit den log-transformierten Variablen
lm_model_log_ohneA <- lm(PREMIUM_LOG ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                   INSURED_VALUE_LOG + CLAIM_PAID_USD_LOG + PROD_YEAR + SEATS_NUM + CCM_TON_LOG, 
                   data = clean_dat_motor)

# Zusammenfassung des neuen Modells
summary(lm_model_log_ohneA)
Anova(lm_model_log_ohneA, type="II")  # Type II oder III je nach Modellstrukt

#Residuen-Plots für Modell-Diagnose
#Plot der Residuen vs. Fit-Werte
plot(lm_model_log_ohneA$fitted.values, lm_model_log_ohneA$residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

#QQ-Plot der Residuen (Überprüfung der Normalverteilung)
qqnorm(lm_model_log_ohneA$residuals, main = "QQ Plot of Residuals")
qqline(lm_model_log_ohneA$residuals, col = "red")

#Paarweise Streudiagramme der numerischen Variablen (Visualisierung von Variablenbeziehungen)
#pairs(~INSURED_VALUE + PREMIUM + CLAIM_PAID_USD + SEATS_NUM + CCM_TON, data = clean_dat_motor, main = "Scatterplot Matrix")

```


## Poisson
```{r Poisson_Model, cache=TRUE}

# Data preparation: Aggregate the number of claims per combination of vehicle type, insurance type, and production year
claims_per_vehicle_usage_prodyear <- clean_dat_motor %>%
  group_by(TYPE_VEHICLE, INSR_TYPE, PROD_YEAR) %>%
  summarise(Amount_Claims = sum(CLAIM_PAID == "YES"), .groups = 'drop')

# Poisson Regression: Predict the number of claims based on vehicle type, insurance type, and production year
poisson_model <- glm(Amount_Claims ~ TYPE_VEHICLE + INSR_TYPE + PROD_YEAR , 
                               family = poisson, data = claims_per_vehicle_usage_prodyear)

# Summary of the model
summary(poisson_model)

# Model diagnostics and evaluation
# Residuals vs. Fitted Plot
plot(poisson_model$fitted.values, residuals(poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# QQ Plot of residuals (Check for normal distribution)
qqnorm(residuals(poisson_model, type = "deviance"), main = "QQ Plot of Residuals")
qqline(residuals(poisson_model, type = "deviance"), col = "red")

# Visualization of predicted claim rates by vehicle type, insurance type, and production year
predicted_values <- data.frame(claims_per_vehicle_usage_prodyear,
                               Predicted_Claims = predict(poisson_model, type = "response"))

ggplot(predicted_values, aes(x = TYPE_VEHICLE, y = Predicted_Claims, fill = INSR_TYPE)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
  labs(title = "Predicted Number of Claims by Vehicle Type, Insurance Type, and Production Year",
       x = "Vehicle Type", y = "Predicted Number of Claims") +
  theme_minimal() +
  facet_wrap(~PROD_YEAR)


```
Overdispersion!!!!!!!!!

### Massnahme:Interaktionen?

```{r pois_interact, cache=TRUE}

# Creating an interaction plot
ggplot(claims_per_vehicle_usage_prodyear, aes(x = PROD_YEAR, y = Amount_Claims, color = INSR_TYPE, group = INSR_TYPE)) +
  geom_line(size = 1) +  # Line plot for each insurance type (INSR_TYPE)
  geom_point(size = 2) + # Points for each observation
  labs(title = "Interaction Plot between Production Year and Vehicle Usage",
       x = "Production Year", 
       y = "Number of Claims") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  facet_wrap(~ TYPE_VEHICLE)  # Facet for each vehicle type

# Poisson model with interactions between production year and insurance type
poisson_model_interaction2 <- glm(Amount_Claims ~ TYPE_VEHICLE * INSR_TYPE + PROD_YEAR, 
                                  family = poisson, data = claims_per_vehicle_usage_prodyear)

# Summary of the model
summary(poisson_model_interaction2)

# Residuals vs Fitted Plot
plot(poisson_model_interaction2$fitted.values, residuals(poisson_model_interaction2, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Poisson with Interaction)")
abline(h = 0, col = "red")

# QQ Plot
qqnorm(residuals(poisson_interaction_model, type = "deviance"), main = "QQ Plot of Residuals (Poisson with Interaction)")
qqline(residuals(poisson_interaction_model, type = "deviance"), col = "red")



```


### Massnahme: Quasi-Poisson-Regression


```{r quasiPois, cache=TRUE}

# Quasi-Poisson regression: Predicting the number of claims based on vehicle type, usage, and production year
quasi_poisson_model <- glm(Amount_Claims ~ TYPE_VEHICLE + INSR_TYPE + PROD_YEAR, 
                           family = quasipoisson, data = claims_per_vehicle_usage_prodyear)

# Summary of the model
summary(quasi_poisson_model)

# Model diagnostics: Residuals vs. Fitted Plot
plot(quasi_poisson_model$fitted.values, residuals(quasi_poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Quasi-Poisson)")
abline(h = 0, col = "red")

# QQ plot of residuals (checking normality)
qqnorm(residuals(quasi_poisson_model, type = "deviance"), main = "QQ Plot of Residuals (Quasi-Poisson)")
qqline(residuals(quasi_poisson_model, type = "deviance"), col = "red")

# Visualization of the predicted claim rates by vehicle type, usage, and production year
predicted_values_qp <- data.frame(claims_per_vehicle_usage_prodyear,
                                  Predicted_Claims = predict(quasi_poisson_model, type = "response"))

ggplot(predicted_values_qp, aes(x = TYPE_VEHICLE, y = Predicted_Claims, fill = INSR_TYPE)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
  labs(title = "Predicted Number of Claims by Vehicle Type, Usage, and Production Year (Quasi-Poisson)",
       x = "Vehicle Type", y = "Predicted Number of Claims") +
  theme_minimal() +
  facet_wrap(~PROD_YEAR)



```



## Binomial
```{r Binomial_Model, cache=TRUE}
# TODO

```

## Generalised Additive Model (GAM)
```{r GAM, cache=TRUE}
# TODO

```

## Neural Network
```{r Neural_Network, cache=TRUE}
# TODO

```


## Support Vector Machine (SVM)
```{r SVM, cache=TRUE}
# TODO

```


# Conclusion





