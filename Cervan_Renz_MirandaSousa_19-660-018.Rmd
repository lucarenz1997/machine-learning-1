---
title: "ML1"
authors: "Alvaro Cervan, Luca Renz, Rafaella Miranda-Sousa"
date: "2024-01-10"
output:
  word_document: default
pdf_document: default
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load_packages, echo =FALSE, cache=TRUE}

#Install and import libraries.
if (!require("car")) install.packages("car")  # Support Vector Machine (SVM)
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("ROI")) install.packages("ROI")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("corrplot")) install.packages("corrplot")
if (!require("dplyr")) install.packages("dplyr")
if (!require("GGally")) install.packages("GGally")
if (!require("mgcv")) install.packages("mgcv")  # Generalised Additive Model (GAM)
if (!require("nnet")) install.packages("nnet")  # Neural Networks
if (!require("e1071")) install.packages("e1071")  # Support Vector Machine (SVM)
if (!require("MASS")) install.packages("MASS")
if (!require("arm")) install.packages("arm")

library(car)
library(readr,quietly = T)
library(ggplot2, quietly = T)
library(ROI, quietly = T)
library(tidyverse, quietly = T)
library(lubridate, quietly = T)
library(corrplot, quietly = T)
library(dplyr)
library(GGally)
library(mgcv)  # For Generalised Additive Models
library(nnet)  # For Neural Networks
library(e1071)  # For Support Vector Machine
library(arm)

```
Notizen Rafi
SVM Teil:
  Cross validation or other methods for model comparing must be used on one single
methods (e.g. you use Cross Validation to compare 2-3 SVM models).
• Students are free to choose a measure of fit that they find more appropriate.
• In case students cannot find an appropriate measure of fit, they can use the Root Mean
Squared Error (RMSE).

Schliesslich ist zu beachten, dass die Zusammenstellung von Dokumenten einige Zeit in Anspruch nehmen kann... insbesondere wenn komplexe
Modelle angepasst werden
- In diesen Fällen können Sie die Argumentationsoption cache = TRUE verwenden, so dass ein Chunk nur dann neu ausgewertet wird
nur dann neu ausgewertet wird, wenn er seit der letzten Kompilierung geändert wurde. Wenn der Chunk unverändert blieb
unverändert, dann werden die alten Ergebnisse verwendet



# Data Preprocessing

Aus Quelle:
  Some predictors such as carrying capacity and seat number are removed from the dataset prior
to data analysis and modeling since they are not correctly coded.


CHATGPT
CCM TON
Es macht keinen Sinn, dass Fahrzeuge einen Wert von 0 für die Variable CCM_TON haben, wenn diese Variable den Hubraum oder das Gewicht des Motors in Kubikzentimetern (ccm) oder Tonnen angibt.
Warum?
  Der Hubraum (ccm) gibt das Volumen der Zylinder eines Verbrennungsmotors an. Ein Wert von 0 wäre unplausibel, da ein Fahrzeug ohne Hubraum keinen funktionsfähigen Motor hätte.
Wenn CCM_TON das Gewicht des Motors in Tonnen angibt, wäre ebenfalls ein Wert von 0 unplausibel, da ein Fahrzeug ohne Motorgewicht nicht funktionsfähig wäre.

```{r data_prep, echo=FALSE, cache=TRUE}

# DATA LOAD
raw_dat_motor <- read_csv("data/motor_data14-2018.csv", show_col_types = FALSE)

dim(raw_dat_motor)
str(raw_dat_motor)

#DATA PREP

#EFFECTIVE_YR
#Entfernen der Spalte EFFECTIVE_YR (Hat keinen Nutzen, da nicht entziffert werden kann)
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "EFFECTIVE_YR")]

#CARRYING_CAPACITY
#Entfernen der Spalte CARRYING_CAPACITY
raw_dat_motor <- raw_dat_motor[ , !(names(raw_dat_motor) %in% "CARRYING_CAPACITY")]

#CLAIM_PAID
raw_dat_motor$CLAIM_PAID_USD <- ifelse(is.na(raw_dat_motor$CLAIM_PAID), 0, raw_dat_motor$CLAIM_PAID)
raw_dat_motor$CLAIM_PAID <- ifelse(raw_dat_motor$CLAIM_PAID_USD == 0, "NO", "YES")

# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

#SEX
raw_dat_motor$SEX <- factor(raw_dat_motor$SEX, 
                            levels = c(0, 1, 2), 
                            labels = c("Legal entity", "Male", "Female"))
table(raw_dat_motor$SEX)

#INSR_BEGIN
raw_dat_motor$INSR_BEGIN <- dmy(raw_dat_motor$INSR_BEGIN)

#INSR_END
raw_dat_motor$INSR_END <- dmy(raw_dat_motor$INSR_END)

#INSR_TYPE
raw_dat_motor$INSR_TYPE <- factor(raw_dat_motor$INSR_TYPE, 
                                  levels = c(1201, 1202, 1204), 
                                  labels = c("Private", "Commercial", "Motor trade road risk"))

#INSURED_VALUE
#Überprüfen der Anzahl der fehlenden Werte
missing_values <- sum(is.na(raw_dat_motor$INSURED_VALUE))
cat("Fehlende Werte in INSURED_VALUE:", missing_values, "\n")

#Zusammenfassung der statistischen Kennzahlen
summary_stats <- summary(raw_dat_motor$INSURED_VALUE)
cat("Zusammenfassung der statistischen Kennzahlen von INSURED_VALUE:\n")
print(summary_stats)

#Ermittlung der Anzahl der Einträge, die 0 als Wert haben
zero_values <- sum(raw_dat_motor$INSURED_VALUE == 0, na.rm = TRUE)
cat("Anzahl der Einträge mit dem Wert 0 in INSURED_VALUE:", zero_values, "\n")

#Überprüfe, wie viele Datensätze betroffen sind
zero_insured_value <- raw_dat_motor[raw_dat_motor$INSURED_VALUE == 0, ]
cat("Anzahl der Datensätze mit INSURED_VALUE = 0:", nrow(zero_insured_value), "\n")

#Zusammenfassung der betroffenen Datensätze nach verschiedenen Variablen, um Muster zu erkennen
cat("Verteilung der Versicherungstypen (INSR_TYPE) bei INSURED_VALUE = 0:\n")
table(raw_dat_motor$INSR_TYPE) #Alle
print(table(zero_insured_value$INSR_TYPE)) #nur 0

cat("\nVerteilung der Fahrzeugtypen (TYPE_VEHICLE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$TYPE_VEHICLE))

cat("\nVerteilung der Fahrzeugnutzung (USAGE) bei INSURED_VALUE = 0:\n")
print(table(zero_insured_value$USAGE))

#Statistische Kennzahlen für andere Variablen bei INSURED_VALUE = 0 (z.B. PREMIUM)
cat("\nZusammenfassung der Prämien (PREMIUM) bei INSURED_VALUE = 0:\n")
summary(zero_insured_value$PREMIUM)

#Visualisierung der Fahrzeugnutzung bei INSURED_VALUE = 0
ggplot(zero_insured_value, aes(x = USAGE)) +
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Verteilung der Fahrzeugnutzung bei INSURED_VALUE = 0", x = "Fahrzeugnutzung", y = "Anzahl") +
  theme_minimal()

#Fazit: Es wurde kein Zusammenhang festgestellt. Vermutlich ist der Versicherungswert von 0 darauf zurückzuführen, dass gesetzlich nur eine Haftpflichtversicherung erforderlich ist. In diesen Fällen gibt es keinen festgelegten Wert für Schäden am Fahrzeug selbst. Daher werden Datensätze mit einem INSURED_VALUE von 0 aus der Analyse entfernt, da sie keine relevanten Informationen für die Bewertung von Fahrzeugwerten enthalten.

#Entfernen der Zeilen, bei denen INSURED_VALUE gleich 0 ist
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE != 0, ]

#Überprüfen, ob die Zeilen erfolgreich entfernt wurden
cat("Anzahl der verbleibenden Datensätze:", nrow(raw_dat_motor), "\n")

#Verteilung von INSURED_VALUE visualisieren (Histogramm)
ggplot(raw_dat_motor, aes(x = INSURED_VALUE)) +
  geom_histogram(binwidth = 50000, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Verteilung von INSURED_VALUE", x = "Versicherter Wert", y = "Häufigkeit") +
  theme_minimal()

#Boxplot zur Identifizierung von Ausreissern
ggplot(raw_dat_motor, aes(y = INSURED_VALUE)) +
  geom_boxplot(fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "Boxplot von INSURED_VALUE", y = "Versicherter Wert") +
  theme_minimal()

#Überprüfung der statistischen Kennzahlen ohne die 0-Werte
cat("Zusammenfassung der statistischen Kennzahlen ohne 0-Werte:\n")
print(summary(raw_dat_motor$INSURED_VALUE))

#Verteilung der log-transformierten INSURED_VALUE (nur für nicht-null Werte)
ggplot(raw_dat_motor[raw_dat_motor$INSURED_VALUE > 0, ], aes(x = log(INSURED_VALUE))) +
  geom_histogram(binwidth = 0.2, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Log-transformierte Verteilung von INSURED_VALUE (ohne Nullwerte)", x = "log(Versicherter Wert)", y = "Häufigkeit") +
  theme_minimal()

summary(raw_dat_motor$INSURED_VALUE)

#Ausreisser INSURED_VALUE entfernen 
raw_dat_motor <- raw_dat_motor[raw_dat_motor$INSURED_VALUE >= 10, ]
summary(raw_dat_motor$INSURED_VALUE)

#Workspace
rm(zero_insured_value)

#PREMIUM
#Uberpruefung ob entfernen von PREMIUM = 0 vom Datensatz valide ist
data.frame(
  PREMIUM_0_Percent = round(100 * sum(raw_dat_motor$PREMIUM == 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_NA_Percent = round(100 * sum(is.na(raw_dat_motor$PREMIUM)) / sum(!is.na(raw_dat_motor$PREMIUM)), 4),
  PREMIUM_MORE_Percent = round(100 * sum(raw_dat_motor$PREMIUM > 0, na.rm = TRUE) / sum(!is.na(raw_dat_motor$PREMIUM)), 4)
)

#Entfernen der Zeilen, bei denen PREMIUM NA oder 0 ist
raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$PREMIUM) | raw_dat_motor$PREMIUM == 0), ]


# Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
# Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")

# OBJECT_ID
# Anzahl der Gesamtzeilen im Datensatz
total_rows <- nrow(raw_dat_motor)

# Anzahl der einzigartigen OBJECT_IDs
unique_object_ids <- length(unique(raw_dat_motor$OBJECT_ID))

# Überprüfen, ob OBJECT_IDs einmalig sind
if (total_rows == unique_object_ids) {
  cat("Die OBJECT_IDs sind einmalig.\n")
} else {
  cat("Die OBJECT_IDs sind NICHT einmalig.\n")
  cat("Anzahl der Duplikate:", total_rows - unique_object_ids, "\n")
  
  # Häufigkeit der OBJECT_IDs
  object_id_counts <- table(raw_dat_motor$OBJECT_ID)
  
  # Durchschnittliche und maximale Häufigkeit von OBJECT_ID
  avg_object_id_freq <- mean(object_id_counts)
  max_object_id_freq <- max(object_id_counts)
  
  cat("Durchschnittliche Häufigkeit der OBJECT_ID:", round(avg_object_id_freq, 3), "\n")
  cat("Maximale Häufigkeit der OBJECT_ID:", max_object_id_freq, "\n")
  
  # Häufigkeit der Kombination von OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE und PREMIUM
  combo_counts <- raw_dat_motor %>%
    group_by(OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM) %>%
    summarise(count = n(), .groups = 'drop')
  
  # Durchschnittliche und maximale Häufigkeit der Kombination
  avg_combo_freq <- mean(combo_counts$count) # Durchschnittliche Häufigkeit der Kombination
  max_combo_freq <- max(combo_counts$count)   # Maximale Häufigkeit der Kombination
  
  cat("Durchschnittliche Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", round(avg_combo_freq, 3), "\n")
  cat("Maximale Häufigkeit der Kombination (OBJECT_ID, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM):", max_combo_freq, "\n")
}

#Teilweise gibt es bei CLAIM_PAID== YES eine vervielfachung
#Korrektur bzw. entfernen dieser mehrfachen Zeilen
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSR_TYPE, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  # Zähle die Anzahl der Zeilen in jeder Gruppe
  mutate(group_size = n()) %>%
  ungroup() %>%
  # Entferne Zeilen nur, wenn es eine Doppelzeile gibt und CLAIM_PAID == "NO" und CLAIM_PAID_USD <= 1
  filter(!(group_size > 1 & CLAIM_PAID == "NO" & CLAIM_PAID_USD <= 1)) %>%
  dplyr::select(-group_size)  # Entferne die Hilfsspalte

#Korrektur Wiederspruch bei INSR_TYPE
raw_dat_motor <- raw_dat_motor %>%
  group_by(SEX, INSR_BEGIN, INSR_END, INSURED_VALUE, PREMIUM, OBJECT_ID, PROD_YEAR, SEATS_NUM, TYPE_VEHICLE, CCM_TON, MAKE, USAGE) %>%
  filter(!(n() > 1 & INSR_TYPE != "Commercial")) %>%  # Behalte nur die Zeilen mit "Commercial"
  ungroup()  # Ungroup, um das Gruppierungsobjekt zu entfernen

# Clear Workspace
rm(list = setdiff(ls(), "raw_dat_motor"))


#PROD_YEAR
#Zeilen mit PROD_YEAR NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$PROD_YEAR),]
summary(raw_dat_motor$PROD_YEAR)

#SEATS_NUM
#Analyse SEATS_NUM: Anzahl der Zeilen mit SEATS_NUM == 0, NA und anderen Werten
data.frame(
  SEATS_NUM_0 = sum(raw_dat_motor$SEATS_NUM == 0, na.rm = TRUE),
  SEATS_NUM_NA = sum(is.na(raw_dat_motor$SEATS_NUM)),
  SEATS_NUM_OTHER = sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE)
)
#Relativ: Prozentsatz der Zeilen mit SEATS_NUM == 0, NA oder anderen Werten
data.frame(
  SEATS_NUM_0_or_NA_Percent = 100 * sum(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0) / nrow(raw_dat_motor),
  SEATS_NUM_OTHER_Percent = 100 * sum(raw_dat_motor$SEATS_NUM > 0, na.rm = TRUE) / nrow(raw_dat_motor)
)
#Zeilen mit SEATS_NUM NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$SEATS_NUM),]
summary(raw_dat_motor$SEATS_NUM)

#Problematik: Es gibt SEATS_NUM mit 0

##Erstellen separater Datensätze für SEATS_NUM == 0 und SEATS_NUM > 0
#data_seats_num_0 <- subset(raw_dat_motor, SEATS_NUM == 0)
#data_seats_num_other <- subset(raw_dat_motor, SEATS_NUM > 0 & !is.na(SEATS_NUM))
## Tabellen der Fahrzeugtypen für beide Datensätze
#table(data_seats_num_0$TYPE_VEHICLE)
#table(data_seats_num_other$TYPE_VEHICLE)

##SEATS_NUM Alternative 1: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
##Liste der Fahrzeugtypen, bei denen SEATS_NUM == 0 unplausibel ist (Trailers and semitrailers, Tractor, Tanker werden gelassen)
#unplausible_types <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Station Wagones", "Tanker", "Truck")
##Entfernen der Zeilen, bei denen SEATS_NUM == 0 und der Fahrzeugtyp unplausibel ist
#raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$SEATS_NUM == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types), ]
#
#
##SEATS_NUM Alternative 2: Entfernen der Zeilen wo SEATS_NUM 0 oder NULL ist
#raw_dat_motor <- raw_dat_motor[!(is.na(raw_dat_motor$SEATS_NUM) | raw_dat_motor$SEATS_NUM == 0), ]
#
##SEATS_NUM Alternative 3: Entfernen der SEATS_NUM-Spalte, da viele NA und schlechte Datenqualität
##raw_dat_motor <- subset(raw_dat_motor, select = -SEATS_NUM)

#TYPE_VEHICLE
#Entfernen der Zeilen, bei denen TYPE_VEHICLE == "Trade plates" Da zu wenige Auspraegungen (5)
#table(raw_dat_motor$TYPE_VEHICLE)
raw_dat_motor <- raw_dat_motor[raw_dat_motor$TYPE_VEHICLE != "Trade plates", ]

#CCM_TON
summary(raw_dat_motor$CCM_TON)
#Relativ CCM_TON 0
data.frame(
  CCM_TON_0_Percent = 100 * mean(raw_dat_motor$CCM_TON == 0, na.rm = TRUE),
  CCM_TON_MORE_Percent = 100 * mean(raw_dat_motor$CCM_TON > 0, na.rm = TRUE))
# Erstellen separater Datensätze für CCM_TON == 0 und CCM_TON > 0
data_CCM_TON_0 <- subset(raw_dat_motor, CCM_TON == 0)
data_CCM_TON_other <- subset(raw_dat_motor, CCM_TON > 0 & !is.na(CCM_TON))
# Tabellen der Fahrzeugtypen für beide Datensätze
table(data_CCM_TON_0$TYPE_VEHICLE)
table(data_CCM_TON_other$TYPE_VEHICLE)
# Liste der Fahrzeugtypen, bei denen CCM_TON == 0 unplausibel ist (Tractor,Trailers and semitrailers werden gelassen)
unplausible_types_ccm <- c("Automobile", "Bus", "Motor-cycle", "Pick-up", "Truck", "Station Wagones", "Tanker", "Special construction")
# Entfernen der Zeilen, bei denen CCM_TON == 0 und der Fahrzeugtyp unplausibel ist
raw_dat_motor <- raw_dat_motor[!(raw_dat_motor$CCM_TON == 0 & raw_dat_motor$TYPE_VEHICLE %in% unplausible_types_ccm), ]


#USAGE
#table(raw_dat_motor$USAGE)
#Wenige Ausprägungen entfernen
raw_dat_motor <- subset(raw_dat_motor, !(USAGE %in% c("Fire fighting", "Learnes", "Others")))



#MAKE
#Zeilen mit MAKE NA entfernen
raw_dat_motor <- raw_dat_motor[!is.na(raw_dat_motor$MAKE),]
#MAKE in Grossbuchstaben umwandeln
raw_dat_motor$MAKE <- toupper(raw_dat_motor$MAKE)

#Entfernen von Duplikaten und Zählen der entfernten Zeilen
removed_count <- nrow(raw_dat_motor) - nrow(raw_dat_motor <- distinct(raw_dat_motor))
#Ausgabe der Anzahl der entfernten Duplikate
cat("Anzahl der entfernten Duplikate:", removed_count, "\n")
# Behalten von Zeilen, in denen MAKE mit Buchstaben beginnt
raw_dat_motor <- raw_dat_motor[grepl("^[A-Za-z]", raw_dat_motor$MAKE), ]
table(raw_dat_motor$MAKE)


#Manuelle Korrekturen von MAKE
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PORCHE", "FORSCHE")] <- "PORSCHE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE == "YAMHA"] <- "YAMAHA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("VOLKSWAGON", "VOLKS WAGON")] <- "VOLKSWAGEN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("TOYOTAA", "TOYOTA*", "TOYTA", "TOYOTA AUTOMOBILE",
                                             "TOYATA", "T0Y0TA", "COMPACT YARIS", "YARIS",
                                             "LAND CRUISER", "VITZ")] <- "TOYOTA"
raw_dat_motor$MAKE[grepl("^TOYOTA", raw_dat_motor$MAKE)] <- "TOYOTA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("NISAN", "NISSAN*")] <- "NISSAN"
raw_dat_motor$MAKE[grepl("^NISSAN", raw_dat_motor$MAKE)] <- "NISSAN"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENGE  ROVER", "RANGEROVER")] <- "RANGE ROVER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("RENALT", "RENUALT", "RENAULT/STOLARCZYK", "RENAULT*")] <- "RENAULT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("PEUGEOUT", "PEJOT", "PAGOT")] <- "PEUGEOT"
raw_dat_motor$MAKE[grepl("^PEUGEOT", raw_dat_motor$MAKE)] <- "PEUGEOT"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("BMB")] <- "BMW"
raw_dat_motor$MAKE[grepl("^BMW", raw_dat_motor$MAKE)] <- "BMW"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MISTIBUSH", "MITSUBISHI*", "MITSUBUSHI")] <- "MITSUBISHI"
raw_dat_motor$MAKE[grepl("^FORD", raw_dat_motor$MAKE)] <- "FORD"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SPORTAGE")] <- "KIA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MERCEEDES", "MERCEEDICE", "MERCEDICE", "MERCHEDES")] <- "MERCEDES"
raw_dat_motor$MAKE[grepl("^MERCEDES", raw_dat_motor$MAKE)] <- "MERCEDES"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("SUZIKE")] <- "SUZUKI"
raw_dat_motor$MAKE[grepl("^SUZUKI", raw_dat_motor$MAKE)] <- "SUZUKI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HYUNDI GETZ")] <- "HYUNDAI"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("ISUSU")] <- "ISUZU"
raw_dat_motor$MAKE[grepl("^ISUZU", raw_dat_motor$MAKE)] <- "ISUZU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("FRANKUN IVECO")] <- "IVECO"
raw_dat_motor$MAKE[grepl("^IVECO", raw_dat_motor$MAKE)] <- "IVECO"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LANDROVER")] <- "LAND ROVER"


raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DONGFANG", "DONFING", "DONG FENGSHEN", "DONG FENG")] <- "DONGFENG"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MAHANDRA")] <- "MAHINDRA"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("HOLAND CAR")] <- "ABAY"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("CALABRASE")] <- "CALABRESE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("GELYION", "GENLION", "GELION", "GENLYONIVECO", "HONGYAN")] <- "GENLYON"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DHATSU", "DIATSU", "DIAHATSU")] <- "DAIHATSU"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("DAWOO", "DAWWO", "DEAWOO", "DEAWOO USE")] <- "DAEWOO"
raw_dat_motor$MAKE[grepl("^LIFAN", raw_dat_motor$MAKE)] <- "LIFAN"
raw_dat_motor$MAKE[grepl("^BAIC", raw_dat_motor$MAKE)] <- "BAIC"
raw_dat_motor$MAKE[grepl("^LOADER", raw_dat_motor$MAKE)] <- "LOADER"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("MOTOR CYCLE", "MOTOR  CYCLE")] <- "MOTORCYCLE"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("AUTO", "AUTOMOBIL")] <- "AUTOMOBILE"
raw_dat_motor$MAKE[grepl("^CATERPILLAR", raw_dat_motor$MAKE)] <- "CATERPILLAR"
raw_dat_motor$MAKE[raw_dat_motor$MAKE %in% c("LIBER DOZER", "LIBERR MOBILE CRANE",
                                             "LIEBERR MOBILE CRANE", "LEABER CATO CRANE",
                                             "LEBHER CRANE", "CRANE LEBEHER",
                                             "CRANE LEBHERER", "LIBER", "LIBEHER CRANE",
                                             "LIBERR MOBILECRANE", "CRANELEBHER")] <- "LIEBHERR"

#table(raw_dat_motor$MAKE)

#Zähle die Anzahl der Einträge pro MAKE, wo CLAIM_PAID == "YES"
count_claims_paid <- raw_dat_motor %>%
  group_by(MAKE, CLAIM_PAID ) %>%                 # Gruppiere nach MAKE
  summarise(count = n()) %>%        # Zähle die Einträge pro Gruppe
  arrange(desc(count)) 

###############################################################################################


#Liste der gewünschten Fahrzeughersteller (Make)
selected_makes <- c("TOYOTA", "ISUZU", "NISSAN", "IVECO", "SINO HOWO", 
                    "MITSUBISHI", "BISHOFTU", "LIFAN", "FORD", "HYUNDAI", 
                    "MAZDA", "GEELY", "DAEWOO", "MERCEDES", "TATA", 
                    "FIAT", "SINO", "SUZUKI", "GENLYON", "RENAULT", "VOLVO")

#Filtern des Datensatzes nach den ausgewählten Fahrzeugherstellern
clean_dat_motor <- subset(raw_dat_motor, MAKE %in% selected_makes)

#Wenige Ausprägungen entfernen
#table(clean_dat_motor$SEX) #OK

#table(clean_dat_motor$USAGE)
clean_dat_motor <- subset(clean_dat_motor, !(USAGE %in% c("Agricultural Any Farm",
                                                          "Agricultural Own Farm",
                                                          "Special Construction", "Taxi")))

#table(clean_dat_motor$TYPE_VEHICLE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(TYPE_VEHICLE %in% c("Tractor")))

#table(clean_dat_motor$INSR_TYPE)
#Wenige Ausprägungen entfernen
clean_dat_motor <- subset(clean_dat_motor, !(INSR_TYPE %in% c("Motor trade road risk")))

#table(clean_dat_motor$MAKE)

#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(clean_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

#New Variable: age_vehicle
clean_dat_motor$AGE_VEHICLE <- 2018 - clean_dat_motor$PROD_YEAR
#Entfernen von PROD_YEAR
clean_dat_motor<- clean_dat_motor[,-8]

###############################################################################################

#Vergleich zum Rohdatensatz
#CLAIM_PAID
data.frame(
  CLAIM_PAID_0 = sum(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0 = sum(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

data.frame(
  CLAIM_PAID_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD == 0, na.rm = TRUE),
  CLAIM_PAID_MORE_THAN_0_Percent = 100 * mean(raw_dat_motor$CLAIM_PAID_USD > 0, na.rm = TRUE))

###############################################################################################

#NA
colSums(is.na(raw_dat_motor)) 
colSums(is.na(clean_dat_motor)) 

#Umwandlung der kategorialen Variablen in Factor-Variablen
clean_dat_motor$OBJECT_ID <- as.factor(clean_dat_motor$OBJECT_ID)
clean_dat_motor$SEX <- as.factor(clean_dat_motor$SEX)
clean_dat_motor$INSR_TYPE <- as.character(clean_dat_motor$INSR_TYPE)
clean_dat_motor$INSR_TYPE <- as.factor(clean_dat_motor$INSR_TYPE)
clean_dat_motor$MAKE <- as.factor(clean_dat_motor$MAKE)
clean_dat_motor$USAGE <- as.factor(clean_dat_motor$USAGE)
clean_dat_motor$CLAIM_PAID <- as.factor(clean_dat_motor$CLAIM_PAID)
clean_dat_motor$TYPE_VEHICLE <- as.factor(clean_dat_motor$TYPE_VEHICLE)


# Clear Workspace
rm(list = setdiff(ls(), c("raw_dat_motor", "clean_dat_motor")))
rm(raw_dat_motor)
clean_dat_motor2<- clean_dat_motor

```



# Graphical Data Analysis

```{r graph_data_analysis, cache = TRUE}


boxplot(PREMIUM ~ SEX, data = clean_dat_motor,
main = "Premium against sex",
ylab = "Premium")



boxplot(CLAIM_PAID_USD ~ SEX, data = clean_dat_motor,
main = "Claim paid (USD) against sex",
ylab = "Heart.weight")






```


# Models
## Linear Model

```{r linear_model, cache = TRUE}

#Modell erstellen
lm_model <- lm(PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + INSURED_VALUE + CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + CCM_TON, data = clean_dat_motor)

#Modellzusammenfassung anzeigen
summary(lm_model)
coef(lm_model)

Anova(lm_model, type="II")  # Type II oder III je nach Modellstrukt


vif(lm_model)


# Residuen plotten
plot(lm_model, which=1)  # Residuals vs Fitted
plot(lm_model, which=2)  # Normal Q-Q



#Residuen-Plots für Modell-Diagnose
#Plot der Residuen vs. Fit-Werte
plot(lm_model$fitted.values, lm_model$residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

#QQ-Plot der Residuen (Überprüfung der Normalverteilung)
qqnorm(lm_model$residuals, main = "QQ Plot of Residuals")
qqline(lm_model$residuals, col = "red")


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model) angezeigt)
r_squared <- summary(lm_model)$r.squared
cat("R-squared:", r_squared, "\n")

```


- R-squared= 0,6368, dh. 63,68% der Varianz in der Zielvariablen PREMIUM wird durch die erklärenden Variablen erklärt. Gut, hat aber Verbesserungspotential

- Alle Prädiktoren sind signifikant Pr(>F) <0,05

- Die Estimate-Werte zeigen die Richtung und Stärke des Effekts der jeweiligen Variable auf die PREMIUM
- INSR_TYPEPrivate hat tiefere Premium wie commercial
- Make: Die Marke Toyota hat die teuerste Praemie. Die guenstigste Premium hat die Marke HOWO
- Guenstigsten USAGEOwn Goods teuerste Premium Car Hires 
- teuerste Premium Type: Bus und guenstigsten Trailers and semitrailers
- Insured value und CLAIM_PAID_USD positiver effekt auf premium war zu erwarten


VIF:
Die VIF-Werte (Variance Inflation Factor) geben an, wie stark die Multikollinearität in deinem Modell ist. Hohe VIF-Werte (normalerweise über 5 oder 10) deuten darauf hin, dass einige Prädiktoren stark miteinander korrelieren, was die Stabilität und Interpretierbarkeit des Modells beeinträchtigen kann.
- INSR_TYPE (5.85): Ein VIF-Wert von über 5 deutet auf eine mögliche Multikollinearität hin. Es könnte sinnvoll sein, diese Variable genauer zu untersuchen.

Residuen
Der Residuals vs Fitted-Plot sollte keine Muster aufweisen (d.h. die Residuen sollten zufällig verteilt sein), und der Normal Q-Q-Plot sollte annähernd eine Gerade bilden, um die Normalverteilung der Residuen zu bestätigen.

Der Residuals vs Fitted Plot zeigt eine leicht gebogene Linie sowie eine Ansammlung von Punkten nahe dem Wert 0, begleitet von einigen extremen Ausreissern (mit ID-Nummern markiert). Dieses Muster deutet darauf hin, dass die Annahme der Homoskedastizität, also der gleichmässigen Varianz der Residuen, in diesem Modell nicht erfüllt ist. In einem idealen Modell sollten die Residuen zufällig und gleichmässig um die horizontale Linie bei 0 verteilt sein. Darüber hinaus sind einige Residuen-Punkte deutlich vom Hauptcluster entfernt. Diese Ausreisser könnten extreme Werte darstellen, die das Modell möglicherweise verzerren. Eine genauere Untersuchung dieser Punkte ist empfehlenswert, um zu entscheiden, ob sie aus dem Modell entfernt oder separat behandelt werden sollten. Bei höheren Prämienwerten zeigen die Residuen zudem eine ungleichmässige Verteilung, was darauf hindeutet, dass das Modell für diese höheren Werte keine ausreichende Passgenauigkeit aufweist.

Im Normal Q-Q Plot lässt sich erkennen, dass die Residuen nicht vollständig auf der Linie liegen, die eine perfekte Normalverteilung darstellt. Dies weist darauf hin, dass die Annahme der Normalverteilung der Residuen verletzt ist. Besonders auffällig sind die deutlichen Abweichungen sowohl am unteren als auch am oberen Ende des Plots. Dies deutet auf das Vorhandensein von Ausreissern hin und darauf, dass die Verteilung der Residuen „schwerere Enden“ aufweist, d. h. mehr extreme Werte enthält als in einer Normalverteilung zu erwarten wäre. Die Punkte am Rand des Plots repräsentieren extreme Werte, die signifikant von der angenommenen Normalverteilung abweichen.

Massnahmen:Transformation der Zielvariablen, Ausreisserbehandlung



### Massnahme 1): Ausreisserbehandlung

```{r lm_massnahme_ausreisser, cache=TRUE}

# Standardisierte Residuen berechnen
standardized_resid <- rstandard(lm_model)

# Schwellenwert für Ausreisser setzen (z.B. Residuen grösser als 3 oder kleiner als -3)
threshold <- 3

# Indizes der Ausreisser identifizieren
outliers <- which(abs(standardized_resid) > threshold)

# Daten ohne Ausreisser
clean_data_no_outliers <- clean_dat_motor[-outliers, ]

# Neues Modell ohne Ausreisser anpassen
lm_model_no_outliers <- lm(PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + INSURED_VALUE + CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + CCM_TON, data = clean_data_no_outliers)

# Zusammenfassung des neuen Modells anzeigen
summary(lm_model_no_outliers)

# Residuenplots für das neue Modell erstellen
par(mfrow = c(2, 2))  # Mehrere Plots auf einer Seite
plot(lm_model_no_outliers)




```

Nach dem Entfernen der Ausreisser zeigen die Residuenplots zwar eine Verbesserung, jedoch bleiben einige Auffälligkeiten bestehen. Der Residuals vs Fitted Plot weist weiterhin eine Trichterform auf, was auf eine Verletzung der Homoskedastizitätsannahme hindeutet. Dies deutet darauf hin, dass die Varianz der Residuen nicht konstant ist. Im Normal Q-Q Plot sind an den Enden deutliche Abweichungen von der theoretischen Normalverteilung zu erkennen, was auf verbleibende Ausreisser oder eine unzureichende Anpassung an die Normalverteilungsannahme schliessen lässt. Der Scale-Location Plot bestätigt ebenfalls eine ungleichmässige Streuung der Residuen, insbesondere bei höheren fitted values. Insgesamt legen diese Ergebnisse nahe, dass eine Transformation der Zielvariablen, wie eine Log-Transformation, sinnvoll sein könnte, um die Modellgüte weiter zu verbessern und die Annahmen der linearen Regression besser zu erfüllen.

Die Modellgüte hat sich verbessert: Der Residual Standard Error (RSE) verringerte sich von über 7700 auf 6168, und das R-squared stieg von 0,6368 auf 0,7175. Dies bedeutet, dass nun 71,75% der Varianz in der Prämie durch die erklärenden Variablen erklärt werden. Die meisten Variablen, wie INSURED_VALUE und CLAIM_PAID_USD, bleiben weiterhin signifikant.



### Massnahme 2): Transformation

```{r lm_massnahme_transf, cache=TRUE}

#Analyse Variablen
numeric_vars <- c("PREMIUM", "INSURED_VALUE", "CLAIM_PAID_USD", "AGE_VEHICLE", "SEATS_NUM", "CCM_TON")

#Histogramme erstellen
par(mfrow = c(2, 3))  # 2 Zeilen, 3 Spalten für die Plots
for (var in numeric_vars) {
  hist(clean_dat_motor[[var]], main = paste("Histogram of", var), xlab = var, col = "lightblue", breaks = 30)
}
par(mfrow = c(1, 1))  # Zurück zu einem einzelnen Plot pro Seite

#Massnahme: Transformation der Variablen
# Log-Transformation für stark rechtsschiefe Variablen
clean_dat_motor$PREMIUM_LOG <- log(clean_dat_motor$PREMIUM + 1)  # Hinzufügen von +1 um log(0) zu vermeiden
clean_dat_motor$INSURED_VALUE_LOG <- log(clean_dat_motor$INSURED_VALUE + 1)
clean_dat_motor$CLAIM_PAID_USD_LOG <- log(clean_dat_motor$CLAIM_PAID_USD + 1)
clean_dat_motor$CCM_TON_LOG <- log(clean_dat_motor$CCM_TON + 1)


```

Die Histogramme der Variablen zeigen, dass einige von ihnen, insbesondere PREMIUM, INSURED_VALUE, CLAIM_PAID_USD und CCM_TON, stark rechtsschief verteilt sind. Diese Verteilungen deuten darauf hin, dass eine log-Transformation sinnvoll sein könnte, um die Daten zu normalisieren und die Varianz zu stabilisieren. Durch die Transformation würde die Schiefe verringert, was zu einer besseren Modellanpassung führen könnte.

Variablen wie AGE_VEHICLE und SEATS_NUM zeigen hingegen eine weniger ausgeprägte Schiefe, sodass eine Transformation hier weniger notwendig erscheint. Eine log-Transformation der stark schiefen Variablen wird daher empfohlen, um die Modellgüte weiter zu verbessern.



```{r lm logtrans}

# Zunächst prüfen, ob es 0-Werte gibt, die das Logarithmieren verhindern
# Kleine Konstante (1) hinzufügen, um mit möglichen 0-Werten in den Variablen umzugehen
clean_data_no_outliers$LOG_PREMIUM <- log(clean_data_no_outliers$PREMIUM + 1)
clean_data_no_outliers$LOG_INSURED_VALUE <- log(clean_data_no_outliers$INSURED_VALUE + 1)
clean_data_no_outliers$LOG_CLAIM_PAID_USD <- log(clean_data_no_outliers$CLAIM_PAID_USD + 1)
clean_data_no_outliers$LOG_CCM_TON <- log(clean_data_no_outliers$CCM_TON + 1)

# Neues Modell mit den logarithmierten Variablen
lm_model_log <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                              LOG_INSURED_VALUE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + LOG_CCM_TON, 
                              data = clean_data_no_outliers)

# Zusammenfassung des neuen Modells anzeigen
summary(lm_model_log)
Anova(lm_model_log, type="II")  # Type II oder III je nach Modellstrukt

# Residuenplots für das neue Modell erstellen
par(mfrow = c(2, 2))  # Mehrere Plots auf einer Seite
plot(lm_model_log)


#Modell-Performance Metriken (z.B. R² und MSE)
#Berechnung des Mean Squared Error (MSE)
mse <- mean(lm_model_log$residuals^2)
cat("Mean Squared Error (MSE):", mse, "\n")

#Berechnung des R² (wird auch in summary(lm_model_log) angezeigt)
r_squared <- summary(lm_model_log)$r.squared
cat("R-squared:", r_squared, "\n")

```



### Massnahme 3):  Ausreisser entfernen mit cooks distance

```{r lm_Ausreisser_log, cache=TRUE}

# Berechnung von Cook's Distance für das Modell
cooksd <- cooks.distance(lm_model_log)

# Setze einen Schwellenwert, um Ausreisser zu identifizieren (z.B. 4/n, wobei n die Anzahl der Datenpunkte ist)
threshold <- 4 / nrow(clean_data_no_outliers)

# Identifiziere potenziell einflussreiche Punkte (die Cook's Distance über dem Schwellenwert haben)
influential <- as.numeric(names(cooksd)[(cooksd > threshold)])

# Daten ohne diese einflussreichen Punkte
clean_data_no_outliers_influential_removed <- clean_data_no_outliers[-influential, ]

# Erstelle das Modell erneut ohne die einflussreichen Ausreisser
lm_model_no_influential <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE + USAGE + TYPE_VEHICLE + 
                             LOG_INSURED_VALUE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + LOG_CCM_TON, 
                             data = clean_data_no_outliers_influential_removed)

# Zusammenfassung des neuen Modells
summary(lm_model_no_influential)

# Residuenplots für das neue Modell
par(mfrow = c(2, 2))
plot(lm_model_no_influential)


```

Nach dem Entfernen der einflussreichen Ausreisser zeigt das Modell eine deutliche Verbesserung. Die Residuen im Residuals vs Fitted Plot sind gleichmässiger um die Nulllinie verteilt, was auf eine verbesserte Homoskedastizität hinweist. Der Normal Q-Q Plot zeigt eine gute Annäherung an die Normalverteilung, mit nur geringen Abweichungen an den Enden. Der Scale-Location Plot bestätigt eine weitgehend konstante Varianz der Residuen, während im Residuals vs Leverage Plot nur wenige einflussreiche Datenpunkte verbleiben. Mit einem R-squared von 0,8028 erklärt das Modell nun 80,28% der Varianz, was eine signifikante Verbesserung darstellt.

### Massnahme 4):  Interaktionen? noch nicht fix

```{r lm_interaktion, cache=TRUE}

# Boxplot von LOG_PREMIUM nach MAKE und USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=MAKE, y=LOG_PREMIUM, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen MAKE und USAGE", x = "MAKE", y = "LOG_PREMIUM")

# Boxplot von LOG_PREMIUM nach TYPE_VEHICLE und USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=TYPE_VEHICLE, y=LOG_PREMIUM, fill=USAGE)) + 
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Interaktion zwischen TYPE_VEHICLE und USAGE", x = "TYPE_VEHICLE", y = "LOG_PREMIUM")

# Scatterplot von LOG_INSURED_VALUE und LOG_PREMIUM nach USAGE
ggplot(clean_data_no_outliers_influential_removed, aes(x=LOG_INSURED_VALUE, y=LOG_PREMIUM, color=USAGE)) + 
  geom_point(alpha=0.5) + 
  geom_smooth(method="lm", se=FALSE) +
  labs(title = "Interaktion zwischen LOG_INSURED_VALUE und USAGE", x = "LOG_INSURED_VALUE", y = "LOG_PREMIUM")



# Anpassung eines linearen Modells mit den identifizierten Interaktionen
lm_model_interactions <- lm(LOG_PREMIUM ~ SEX + INSR_TYPE + MAKE * USAGE + TYPE_VEHICLE * USAGE + 
                            LOG_INSURED_VALUE * USAGE + LOG_CLAIM_PAID_USD + AGE_VEHICLE + SEATS_NUM + 
                            LOG_CCM_TON, data = clean_data_no_outliers_influential_removed)

# Zusammenfassung des neuen Modells mit Interaktionen
summary(lm_model_interactions)

# Residuenplots für das neue Modell
par(mfrow = c(2, 2))
plot(lm_model_interactions)



```

Obwohl die Hinzufügung von Interaktionen das Modell in einigen Aspekten verbessert hat, zeigen die Residuenanalysen, dass Heteroskedastizität und Ausreisser weiterhin Probleme darstellen. Mögliche nächste Schritte könnten die Überprüfung und Behandlung dieser einflussreichen Punkte sowie die Anwendung robusterer Regressionstechniken oder zusätzlicher Transformationen umfassen. Darüber hinaus könnte die Untersuchung weiterer Interaktionen oder die Modellierung nichtlinearer Effekte in Betracht gezogen werden, um die Anpassung weiter zu optimieren.


## Poisson

```{r Poisson_Model, cache=TRUE}

#Data preparation: Aggregate the number of claims per combination of vehicle type, insurance type, and production year
dat_amount_claims <- clean_dat_motor %>%
  group_by(SEX, TYPE_VEHICLE, INSR_TYPE, AGE_VEHICLE) %>%
  summarise(Amount_Claims = sum(CLAIM_PAID == "YES"), .groups = 'drop')

hist(dat_amount_claims$Amount_Claims, breaks=100)

mean(dat_amount_claims$Amount_Claims) # calculate mean
var(dat_amount_claims$Amount_Claims)
#The variance is much greater than the mean, which suggests that we will have over-dispersion in the model.

#Poisson Regression:
poisson_model<- glm(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + AGE_VEHICLE, 
                      family = poisson(link = "log"), data = dat_amount_claims)

#Summary of the model
summary(poisson_model)

#Coeff
coef(poisson_model)
exp(coef(poisson_model))

# Model diagnostics and evaluation
# Residuals vs. Fitted Plot
plot(poisson_model$fitted.values, residuals(poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# QQ Plot of residuals (Check for normal distribution)
qqnorm(residuals(poisson_model, type = "deviance"), main = "QQ Plot of Residuals")
qqline(residuals(poisson_model, type = "deviance"), col = "red")

#Diagnose overdispersion
deviance(poisson_model) / df.residual(poisson_model)

#Visualization of predicted claim rates by vehicle type, insurance type, and production year
predicted_values <- data.frame(dat_amount_claims,
                               Predicted_Claims = predict(poisson_model, type = "response"))

ggplot(predicted_values, aes(x = TYPE_VEHICLE, y = Predicted_Claims, fill = INSR_TYPE)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
  labs(title = "Predicted Number of Claims by Vehicle Type, Insurance Type, and Production Year",
       x = "Vehicle Type", y = "Predicted Number of Claims") +
  theme_minimal() +
  facet_wrap(~AGE_VEHICLE)

```
Starke Overdispersion


### Massnahme 1): Quasi-Poisson-Regression

```{r quasiPois, cache=TRUE}

#Quasi-Poisson
quasi_poisson_model <- glm(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + AGE_VEHICLE, 
                           family = quasipoisson, data = dat_amount_claims)

# Summary of the model
summary(quasi_poisson_model)
#F-Test, Vergleiche von geschachtelten Quasi-Likelihood-Modellen (Overdispersion)
drop1(quasi_poisson_model, test= "F")

# Model diagnostics: Residuals vs. Fitted Plot
plot(quasi_poisson_model$fitted.values, residuals(quasi_poisson_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Quasi-Poisson)")
abline(h = 0, col = "red")

# QQ plot of residuals (checking normality)
qqnorm(residuals(quasi_poisson_model, type = "deviance"), main = "QQ Plot of Residuals (Quasi-Poisson)")
qqline(residuals(quasi_poisson_model, type = "deviance"), col = "red")

# Visualization of the predicted claim rates by vehicle type, usage, and production year
predicted_values_qp <- data.frame(claims_per_vehicle_usage_prodyear,
                                  Predicted_Claims = predict(quasi_poisson_model, type = "response"))

ggplot(predicted_values_qp, aes(x = TYPE_VEHICLE, y = Predicted_Claims, fill = INSR_TYPE)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.7) +
  labs(title = "Predicted Number of Claims by Vehicle Type, Usage, and Production Year (Quasi-Poisson)",
       x = "Vehicle Type", y = "Predicted Number of Claims") +
  theme_minimal() +
  facet_wrap(~AGE_VEHICLE)



```
Immernoch starke Overdispersion

### Massnahme 2): Negative-Binomial-Modell

```{r neg_binom_model, cache=TRUE}

# Negative-Binomial-Regression anpassen
neg_bin_model <- glm.nb(Amount_Claims ~ SEX + TYPE_VEHICLE + INSR_TYPE + AGE_VEHICLE, 
                        data = dat_amount_claims)

# Zusammenfassung des Modells anzeigen
summary(neg_bin_model)

# Exponentierte Koeffizienten anzeigen (um Rate Ratios zu interpretieren)
exp(coef(neg_bin_model))

# Konfidenzintervalle für die Koeffizienten
confint(neg_bin_model)


# Devianz und Freiheitsgrade überprüfen (sollte näher an 1 liegen)
deviance(neg_bin_model) / df.residual(neg_bin_model)

# Residuals vs Fitted Plot
plot(neg_bin_model$fitted.values, residuals(neg_bin_model, type = "deviance"),
     xlab = "Fitted Values", 
     ylab = "Deviance Residuals", 
     main = "Residuals vs Fitted (Negative Binomial)")
abline(h = 0, col = "red")

# QQ-Plot der Residuen
qqnorm(residuals(neg_bin_model, type = "deviance"), main = "QQ Plot of Residuals (Negative Binomial)")
qqline(residuals(neg_bin_model, type = "deviance"), col = "red")

```

The overdispersion was corrected in the model.

In the residuals vs fitted plot, the residuals show an acceptable fit, but there is a cluster formation for very small fitted values, which indicates that the model does not optimally capture these values. In addition, outliers occur for larger values, which also indicate modelling problems.

The QQ plot shows that most residuals follow the theoretical normal distribution well, but they deviate at extreme values. However, these deviations are not unusual for count data models.

Overall, the negative binomial model provides a satisfactory fit, but shows weaknesses for extremely small and large values. These problems could be further improved by analysing outliers or using a zero-inflated negative binomial model

The estimated coefficients are for the most part highly significant (p < 0.001), which indicates a strong influence of the predictor variables on the number of claims. Men and women have significantly fewer claims compared to the reference category (rate ratios of 0.35 and 0.11 respectively). Similarly, vehicles such as motorbikes, tankers and trailers show a greatly reduced frequency of claims. Vehicle age also has a significant negative influence, with older vehicles tending to have fewer claims (rate ratio: 0.88).


## Binomial
```{r Binomial_Model, cache=TRUE}
# TODO

```

## Generalised Additive Model (GAM)
```{r GAM, cache=TRUE}
# TODO

```

## Neural Network
```{r Neural_Network, cache=TRUE}
# TODO

```


## Support Vector Machine (SVM)
```{r SVM, cache=TRUE}
# TODO

```


# Conclusion





